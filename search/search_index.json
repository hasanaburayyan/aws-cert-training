{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Lets Get Certified Please feel free to contribute!","title":"Lets Get Certified"},{"location":"#lets-get-certified","text":"Please feel free to contribute!","title":"Lets Get Certified"},{"location":"associate/architect/compute/","text":"Compute you cant build any application without compute power. This is needed to crunch Data can be done with key compute services: EC2 Lambda Elastic Beanstalk","title":"Compute"},{"location":"associate/architect/compute/#compute","text":"you cant build any application without compute power. This is needed to crunch Data can be done with key compute services: EC2 Lambda Elastic Beanstalk","title":"Compute"},{"location":"associate/architect/databases/","text":"Databases The easiest way to think of database is a spread sheet its a reliable way to store and retrieve information Includes: DynamoDB RDS Redshift","title":"Databases"},{"location":"associate/architect/databases/#databases","text":"The easiest way to think of database is a spread sheet its a reliable way to store and retrieve information Includes: DynamoDB RDS Redshift","title":"Databases"},{"location":"associate/architect/ec2/","text":"Elastic Compute Cloud (EC2) Secure resizable compute capacity in the cloud Like a VM only hosted in AWS instead of your own data center Providing you the capacity you want when needed, giving you full control of the server Brief History Launched in 2006 and was complete game changer basically over night. Pay only for what you use, and provides us a way to have NO wasted capacity On Premises Infrastructure 3-5 year contracts 10-20 business days average to get server online large upfront capital expense Pricing Options On Demand Pay by the hour or second Reserved Reserved capacity for up to 1 - 3 years Up to 72% discount on the hourly charge Spot Purchase unused capacity at discount of up to 90% Prices fluctuate with demand Dedicated Most expensive Physical EC2 servers dedicated for your needs On Demand Would be used when you need: Flexibility of Amazon Ec2 without upfront payment or long-term commitment Short term applications with spiky or unpredictable workloads Testing the water with applications being developed or tested for first time Reserved Instances Would be used when you have: Predictable usage Specific capacity requirements Pay up front for discounts! Reserved instances operate within a Region! Convertable RIs Up to 54% off the on demand price and has the option to change to a different RI type of equal or greater value Scheduled RIs Launch within the time window you define. Match your capacity reservation to a predictable recurring schedule that only requires a fraction of a day, week, or month Spot Instances Use when you have flexible start and end times Applications that are only feasible at very low compute prices Have urgent need for large amounts of additional computing capacity Dedicated Hosts Compliance Regulatory requirements that may not support multi-tenant virtualization On-Demand Licensing Great for licensing that does not support multi-tenancy or cloud deployments Reserved Can be purhcased for up to 70% of on-demand price AWS Cli follows this format aws <SERVICE> <COMMAND> example aws s3 ls Will need to have Secret access key as well as access key id supported for linux, windows, and MacOS Exam Tips Ec2 is like a VM hosted in AWS instead of your own data center Wait only minutes not months for instances Pricing options On Demand Pay by the hour or second Spot Purchase unused capacity with great discount but can be terminated Reserved reserve capacity for 1 to 3 years with up to 72% discount Dedicated Compliance or regulatory obligations to meet","title":"EC2"},{"location":"associate/architect/ec2/#elastic-compute-cloud-ec2","text":"Secure resizable compute capacity in the cloud Like a VM only hosted in AWS instead of your own data center Providing you the capacity you want when needed, giving you full control of the server","title":"Elastic Compute Cloud (EC2)"},{"location":"associate/architect/ec2/#brief-history","text":"Launched in 2006 and was complete game changer basically over night. Pay only for what you use, and provides us a way to have NO wasted capacity","title":"Brief History"},{"location":"associate/architect/ec2/#on-premises-infrastructure","text":"3-5 year contracts 10-20 business days average to get server online large upfront capital expense","title":"On Premises Infrastructure"},{"location":"associate/architect/ec2/#pricing-options","text":"On Demand Pay by the hour or second Reserved Reserved capacity for up to 1 - 3 years Up to 72% discount on the hourly charge Spot Purchase unused capacity at discount of up to 90% Prices fluctuate with demand Dedicated Most expensive Physical EC2 servers dedicated for your needs","title":"Pricing Options"},{"location":"associate/architect/ec2/#on-demand","text":"Would be used when you need: Flexibility of Amazon Ec2 without upfront payment or long-term commitment Short term applications with spiky or unpredictable workloads Testing the water with applications being developed or tested for first time","title":"On Demand"},{"location":"associate/architect/ec2/#reserved-instances","text":"Would be used when you have: Predictable usage Specific capacity requirements Pay up front for discounts! Reserved instances operate within a Region!","title":"Reserved Instances"},{"location":"associate/architect/ec2/#convertable-ris","text":"Up to 54% off the on demand price and has the option to change to a different RI type of equal or greater value","title":"Convertable RIs"},{"location":"associate/architect/ec2/#scheduled-ris","text":"Launch within the time window you define. Match your capacity reservation to a predictable recurring schedule that only requires a fraction of a day, week, or month","title":"Scheduled RIs"},{"location":"associate/architect/ec2/#spot-instances","text":"Use when you have flexible start and end times Applications that are only feasible at very low compute prices Have urgent need for large amounts of additional computing capacity","title":"Spot Instances"},{"location":"associate/architect/ec2/#dedicated-hosts","text":"Compliance Regulatory requirements that may not support multi-tenant virtualization On-Demand Licensing Great for licensing that does not support multi-tenancy or cloud deployments Reserved Can be purhcased for up to 70% of on-demand price","title":"Dedicated Hosts"},{"location":"associate/architect/ec2/#aws-cli","text":"follows this format aws <SERVICE> <COMMAND> example aws s3 ls Will need to have Secret access key as well as access key id supported for linux, windows, and MacOS","title":"AWS Cli"},{"location":"associate/architect/ec2/#exam-tips","text":"Ec2 is like a VM hosted in AWS instead of your own data center Wait only minutes not months for instances Pricing options On Demand Pay by the hour or second Spot Purchase unused capacity with great discount but can be terminated Reserved reserve capacity for 1 to 3 years with up to 72% discount Dedicated Compliance or regulatory obligations to meet","title":"Exam Tips"},{"location":"associate/architect/fundementals/","text":"AWS Fundamentals Global Infrastructure Global infrastructure is made up of Regions, AZs, and Edge locations Currently there are 22 Regions and 77 Availability Zones Regions Physical location in world that consists of two or more AZs Regions are just geographical Area. such as Sydney Australia or us-east-2 in the United States. Each Region consists of 2 or more Availability Zones AZs One or more discrete data centers with redundant power networking and connectivity. Area meaningfully separated from each other, based on geographical data Edge Locations Endpoints for AWS that are used for caching content. Currently over 215 edge locations Exam Tips Region is a physical location in world that consists of two or more AZs An Availability zone is a discrete data center, each with redundant power, networking, and connectivity housed in separate facility Edge locations are endpoints for AWS that are used for caching content. Typically consists of CloudFront (Amazons content delivery Network CDN) Always ask yourself this question when thinking about shared responsibility model, \"Can you do this yourself in AWS Management Console?\" If Yes, you are probably responsible If No, AWS is probably responsible Encryption is shared responsibility Compute Services are: EC2, Lambda, Elastic Beanstalk Storage Services are: S3, EBS, EFS, FSx, Storage Gateway Databases Services are: RDS, DynamoDB, Redshift Networking: VPCs, Direct Connect, Route53, API Gateway, AWS Global Accelerator DONT FORGET: Read whitepaper for well architected before taking exam!!","title":"Fundamentals"},{"location":"associate/architect/fundementals/#aws-fundamentals","text":"","title":"AWS Fundamentals"},{"location":"associate/architect/fundementals/#global-infrastructure","text":"Global infrastructure is made up of Regions, AZs, and Edge locations Currently there are 22 Regions and 77 Availability Zones","title":"Global Infrastructure"},{"location":"associate/architect/fundementals/#regions","text":"Physical location in world that consists of two or more AZs Regions are just geographical Area. such as Sydney Australia or us-east-2 in the United States. Each Region consists of 2 or more Availability Zones","title":"Regions"},{"location":"associate/architect/fundementals/#azs","text":"One or more discrete data centers with redundant power networking and connectivity. Area meaningfully separated from each other, based on geographical data","title":"AZs"},{"location":"associate/architect/fundementals/#edge-locations","text":"Endpoints for AWS that are used for caching content. Currently over 215 edge locations","title":"Edge Locations"},{"location":"associate/architect/fundementals/#exam-tips","text":"Region is a physical location in world that consists of two or more AZs An Availability zone is a discrete data center, each with redundant power, networking, and connectivity housed in separate facility Edge locations are endpoints for AWS that are used for caching content. Typically consists of CloudFront (Amazons content delivery Network CDN) Always ask yourself this question when thinking about shared responsibility model, \"Can you do this yourself in AWS Management Console?\" If Yes, you are probably responsible If No, AWS is probably responsible Encryption is shared responsibility Compute Services are: EC2, Lambda, Elastic Beanstalk Storage Services are: S3, EBS, EFS, FSx, Storage Gateway Databases Services are: RDS, DynamoDB, Redshift Networking: VPCs, Direct Connect, Route53, API Gateway, AWS Global Accelerator DONT FORGET: Read whitepaper for well architected before taking exam!!","title":"Exam Tips"},{"location":"associate/architect/iam/","text":"Identity and Access Management (IAM) IAM allows you to manage users and their level of access to the AWS Console Create users to grant permissions to those users Create groups and roles Control access to AWS resources IAM is a global service, so users, groups, roles are all global resource Understanding IAM It is important to understand IAM both for the exam and for the administrating of IAM policies in an organization Securing The Root Account The root account is the email address you sign up for AWS. The root account has full administrative access to AWS. For this reason, it is important to secure this account and not allow anyone access to the account Enable Multi-factor authentication (MFA) Create admin group for users Create users for everyone Permissions with IAM We assign permissions using policy documents, which are made up of JSON. The following is a full admin access to the AWS Console. { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : \"*\" , \"Resource\" : \"*\" } ] } We can assign policy document to: Users (Typically bad practice) Groups (Better Practice) Roles (Best Practice) Amazon Managed Policy Most cases a managed policy will already exist for what you need. Browse the policies for ones prefixed with the AWS Logo Using IAM It is best practice for users to inherit permissions from groups, and just add and remove users from groups and apply IAM policies to groups. Users A physical person should always be 1 user to 1 human being Never share a user with multiple developers By default a new user has 0 permissions or access when created Groups Functions such as administrators developers etc, Contains users Roles Internal usage within AWS Principle of least Privilege Only assign a user the minimum amount of privileges they need to do their job Single Sign On Can use SAML or OpenID Connect Free Syncs Active Directory provided with IAM in AWS Exam Tips Remember you assign permissions using policy documents written in JSON IAM is universal: It does not apply to regions at this time The Root Account: The Account created when you first set up your AWS account. It is all powerful and should not be used in day to day management Access Key ID and secret Access Keys are NOT the same as username and passwords Only get to see these values once so save them or they will need to be rotated Always Set up password rotation! By default users do not get any permissions IAM Federation uses SAML to do AD syncs","title":"IAM"},{"location":"associate/architect/iam/#identity-and-access-management-iam","text":"IAM allows you to manage users and their level of access to the AWS Console Create users to grant permissions to those users Create groups and roles Control access to AWS resources IAM is a global service, so users, groups, roles are all global resource","title":"Identity and Access Management (IAM)"},{"location":"associate/architect/iam/#understanding-iam","text":"It is important to understand IAM both for the exam and for the administrating of IAM policies in an organization","title":"Understanding IAM"},{"location":"associate/architect/iam/#securing-the-root-account","text":"The root account is the email address you sign up for AWS. The root account has full administrative access to AWS. For this reason, it is important to secure this account and not allow anyone access to the account Enable Multi-factor authentication (MFA) Create admin group for users Create users for everyone","title":"Securing The Root Account"},{"location":"associate/architect/iam/#permissions-with-iam","text":"We assign permissions using policy documents, which are made up of JSON. The following is a full admin access to the AWS Console. { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : \"*\" , \"Resource\" : \"*\" } ] } We can assign policy document to: Users (Typically bad practice) Groups (Better Practice) Roles (Best Practice)","title":"Permissions with IAM"},{"location":"associate/architect/iam/#amazon-managed-policy","text":"Most cases a managed policy will already exist for what you need. Browse the policies for ones prefixed with the AWS Logo","title":"Amazon Managed Policy"},{"location":"associate/architect/iam/#using-iam","text":"It is best practice for users to inherit permissions from groups, and just add and remove users from groups and apply IAM policies to groups.","title":"Using IAM"},{"location":"associate/architect/iam/#users","text":"A physical person should always be 1 user to 1 human being Never share a user with multiple developers By default a new user has 0 permissions or access when created","title":"Users"},{"location":"associate/architect/iam/#groups","text":"Functions such as administrators developers etc, Contains users","title":"Groups"},{"location":"associate/architect/iam/#roles","text":"Internal usage within AWS","title":"Roles"},{"location":"associate/architect/iam/#principle-of-least-privilege","text":"Only assign a user the minimum amount of privileges they need to do their job","title":"Principle of least Privilege"},{"location":"associate/architect/iam/#single-sign-on","text":"Can use SAML or OpenID Connect Free Syncs Active Directory provided with IAM in AWS","title":"Single Sign On"},{"location":"associate/architect/iam/#exam-tips","text":"Remember you assign permissions using policy documents written in JSON IAM is universal: It does not apply to regions at this time The Root Account: The Account created when you first set up your AWS account. It is all powerful and should not be used in day to day management Access Key ID and secret Access Keys are NOT the same as username and passwords Only get to see these values once so save them or they will need to be rotated Always Set up password rotation! By default users do not get any permissions IAM Federation uses SAML to do AD syncs","title":"Exam Tips"},{"location":"associate/architect/networking/","text":"Networking A way for our compute storage and databases to communicate and even a place for them to live. Includes: VPCs Direct Connect Route53 API Gateway AWS Global Accelerator","title":"Networking"},{"location":"associate/architect/networking/#networking","text":"A way for our compute storage and databases to communicate and even a place for them to live. Includes: VPCs Direct Connect Route53 API Gateway AWS Global Accelerator","title":"Networking"},{"location":"associate/architect/s3/","text":"Simple Service Storage (S3) What is S3 Object Storage Provides secure, durable, highly scalable object storage Scalable S3 allows you to store and retrieve any amount of data from anywhere on the web at a very low cost Simple Amazon S3 is easy to use with a simple web service interface Manages data as objects rather than in file systems or data blocks Can store: Any type of file Photos, videos, code, documents, and text files Can NOT Store: Operating System Database S3 Basics Unlimited Storage with S3 Objects can be 5TB in size 5GB max single put Buckets are used to store files (similar to folders) Universal Namespaces so S3 bucket names must be globally unique Understanding the S3 URLS Will always be https://BUCKET_NAME.s3.REGION.amazonaws.com/KEY_NAME Example: https://acloudguru.s3.us-east-1.amazonaws.com/my_pic.jpg Key Values Stores Keys: The name of the objects (e.g., my_pic.jpg) Value: The data itself, which is made up of a sequence of bytes Version ID: Important for storing multiple versions of the same object Metadata: Data about the data you are storing (eg. content-type, last-modified, etc) Availability and Durability S3 is built for availability with 99.95% - 99.99% service availability, depending on S3 tier S3 is designed for durability with 99.999999999% (9 decimal places) durability for data stored in S3 Types Standard S3 (Default Type) Highly available and durable. Data is stored redundantly across multiple devices in multiple facilities (>= 3 AZs) Designed for Frequent access! Suitable for most workloads Standard-Infrequent Access 99.9% Availability 99.99999999999% Durability (11 9's) Designed for infrequent accessed data Rapid Access Used for data that is accessed less frequently but requires rapid access when needed Pay to Access to Data This is a low per-GB storage price Has a per-GB retrieval fee Use cases Great for long-term storage, backups, and as a data store for disaster recovery files One Zone-Infrequent Access 99.5% Availability 99.99999999999% Durability (11 9's) Same as Standard-Infrequent Access but only in 1 AZ 20% less than S3 Standard-IA Great for long-lived, infrequently accessed, non-critical data Glacier 99.99% Availability 99.99999999999% Durability (11 9's) Retrieval times that range from 1 minute to 12 hours. Historically should be data accessed a few times a year. Cheap Storage Optimized for data that is VERY infrequently access Primarily used for ARCHIVING Pay each time you access data Glacier Deep Archive 99.99% Availability 99.99999999999% Durability (11 9's) Archive data that is RARELY accessed data with a default retrieval time of 12 hours Intelligent-Tiering 99.99% Availability 99.99999999999% Durability (11 9's) Automatically moves your data based on the amount of times you access data Optimizes cost for monthly fee. Storage Costs Lifecycle Management Defined rules to automatically transition objects to a cheaper storage tier or delete objects that are no longer required after a set period of time Versioning With versioning all versions of an object are stored and can be retrieved, including deleted objects Securing Data Server-Side Encryption Can set default encryption on a bucket to encrypt all new objects that are stored in a bucket Access Control Lists (ACLs) Define which AWS accounts or groups are granted access and type of access. You can attach a S3 ACLs to individual objects within a bucket Bucket Policies S3 bucket polices specify what actions are allowed or denied (allow a user Alice to PUT but not DELETE objects in the bucket) JSON policies ACL vs Bucket Policies Access Control lists are designed to be applied to individual object levels Bucket policies are designed to be applied to entire bucket Data consistency Strong Read-After-Write consistency After a successful write of a new object (PUT) or overwrite of an existing object, any subsequent read request immediately recieves the latest version of the object Strong consistency for list operations, so after a write you can immediately perform a listing of objects in a bucket with all changes reflected. Hosting Static Website In S3 You can use S3 to host static websites. S3 is great for hosting static websites since S3 Scales on demand! Must provide all static files and give index.html location and can optionally provide (error.html) Must apply policy to make objects public Versioning Objects in S3 What is versioning Allows us to have multiple versions in s3 bucket Advantages: Keep all versions of objects in s3 Once enabled cannot be disabled (only suspended) Supports MFA Lifecycle Rules Great for Backup Tools Deletion creates a delete marker and does not actually delete the file. In order to restore a file the delete marker must be deleted. S3 Object Lock You can use s3 object lock to store objects using a Write Once Read Many (WORM) model. It can help prevent objects from being deleted or modified for a fixed amount of time or indefinitely You can use S3 object lock to meet regulatory requirements that require WORM storage, or add an extra layer of protection against objects changes and deletions Governance Mode In governance mode users cant overwrite or delete an object version or alter its lock settings unless they have special permissions. With governance mode you protect objects against being deleted by most users, but you still grant some users permission to alter the retention settings or delete the objects if necessary Compliance Mode (Hardcore) In compliance mode, a protected object version cant be overwritten or deleted by any user INCLUDING the root user in your AWS account. When an object is locked in compliance mode, its retention mode cant be changed and its retention period cant be shortened. Compliance mode ensures an object version cant be overwritten or deleted for the duration of the retention period. Retention Periods A retention period protects an object version for a fixed amount of time. When you place a retention period on an object version, Amazon S3 stores a timestamp in the object version's meta data to indicate when the retention period expires. After retention period expires, the object version can be overwritten or deleted unless you also placed a legal hold on the object version. Legal Holds S3 object lock also enables you to place a legal hold on an object version. Like a retention period a legal hold prevents an object version from being overwritten or deleted. However a legal hold does not have an associated retention period and remains in effect until removed. Legal holds can be freely placed and removed by any user who has the s3:PutObjectLegalHold permission. Glacier Vault Lock A way to apply a WORM model to the entire Glacier bucket S3 Encryption Encryption in Transit SSL/TLS HTTPS Encryption at Rest: Server Side Encryption SSE-S3: S3-managed keys, using AES 256-bit encryption SSE-KMS: AWS Key management service managed keys SSE-C: Customer provided keys Encryption at Rest: Client Side Encryption Encrypt files yourself before uploading files Enforcing Server-Side Encryption Console Server-Side Encryption Select the encryption setting on your S3 bucket. The easiest way is just to checkbox the console Bucket Policy Server-Side Encryption Can enforce encryption using bucket policy To encrypt file at upload time use: x-amz-server-side-encryption If the file is to be encrypted at upload time this parameter will need ot be included in the request header Two Options: AES256 (SSE-S3 - S3 managed keys) aws:kms (SSE-KMS - KMS managed keys) When parameter is included in the header of the PUT request, it tells S3 to encrypt the object at the time of upload using a specified encryption method. So to enforce encryption with Bucket Policies deny any PUT requests that are missing the encryption parameter in the header. S3 Prefixes After our bucket name we can have folders such as BUCKET_NAME/folder1/subfolder1 BUCKET_NAME/folder2/subfolder1 BUCKET_NAME/folder3 Prefix is just the folder pwd and not the file key S3 Performance S3 has extremely low latency. You can get the first byte out of S3 within 100-200 milliseconds You can achieve a high number of requests: 3500 PUT/COPY/POST/DELETE and 5500 GET/HEAD requests per second, per prefix Thus the more prefixes we have in our bucket the more performant it can become S3 Limitation When Using KMS If you are using SSE-KMS to encrypt your objects in S3 you must keep in mind the KMS limit which are Region specific Based on Region requests per second ranges from 5500, 10000, 30000 Uploading and downloading will count towards the KMS quota Currently you can NOT request a quota increase for KMS Uploads Recommended for files over 100 MB and REQUIRED for files over 5 GB Parallelize uploads (increases efficiency) Breaks big file into smaller parts and combines them into S3 Downloads Byte range fetches Parallelize downloads by specifying byte ranges If failure in download its only for specific byte range Backup Data With S3 Replication Used to be called \"Cross Region Replication\" Allows us to replicate objects from one bucket to another Versioning must be turned on in both buckets Objects existing in bucket are NOT automatically replicated Once replication is turned on all subsequent updated objects will be replicated automatically Delete markers are not replicated by default Exam tips S3 is a safe place to store your files The data is spread across multiple devices and facilities to ensure availability and durability Object Based (allows you to upload any file type) NOT for OS or DB storage Max File Size is 5TB Min File size is 0 bytes Unlimited Storage!! Will always be https://BUCKET_NAME.s3.REGION.amazonaws.com/KEY_NAME Successful CLI or API uploads should always generate 200 return code Key: Object Name Value: Data itself Version ID: Allows you to store multiple versions of same object Versioning is not enabled by default because it costs money to store extra copies of data so the user must choose to opt in Metadata: Data about data you are storing (content-type, last-modified) Buckets are private by default Both bucket and object must be public to use! Uploading objects to bucket using CLI or API should always return 200 status code Can serve Static content websites S3 scales on demand Versioning supports MFA to require 2 forms of authorization to delete an object To enforce WORM model use S3 Object Locks Compliance mode stops any user from deleting or modifying objects (even ROOT user) Governance mode stops MOST users from deleting or modifying objects Encryption in transit with (SSL/TLS and HTTPS) Encryption at Rest: SSE (SSE-S3, SSE-KMS, SSE-C) Enforcement of encryption can be done with a bucket policy With replication Delete markers are not replicated by default","title":"S3"},{"location":"associate/architect/s3/#simple-service-storage-s3","text":"","title":"Simple Service Storage (S3)"},{"location":"associate/architect/s3/#what-is-s3","text":"Object Storage Provides secure, durable, highly scalable object storage Scalable S3 allows you to store and retrieve any amount of data from anywhere on the web at a very low cost Simple Amazon S3 is easy to use with a simple web service interface Manages data as objects rather than in file systems or data blocks Can store: Any type of file Photos, videos, code, documents, and text files Can NOT Store: Operating System Database","title":"What is S3"},{"location":"associate/architect/s3/#s3-basics","text":"Unlimited Storage with S3 Objects can be 5TB in size 5GB max single put Buckets are used to store files (similar to folders) Universal Namespaces so S3 bucket names must be globally unique Understanding the S3 URLS Will always be https://BUCKET_NAME.s3.REGION.amazonaws.com/KEY_NAME Example: https://acloudguru.s3.us-east-1.amazonaws.com/my_pic.jpg","title":"S3 Basics"},{"location":"associate/architect/s3/#key-values-stores","text":"Keys: The name of the objects (e.g., my_pic.jpg) Value: The data itself, which is made up of a sequence of bytes Version ID: Important for storing multiple versions of the same object Metadata: Data about the data you are storing (eg. content-type, last-modified, etc)","title":"Key Values Stores"},{"location":"associate/architect/s3/#availability-and-durability","text":"S3 is built for availability with 99.95% - 99.99% service availability, depending on S3 tier S3 is designed for durability with 99.999999999% (9 decimal places) durability for data stored in S3","title":"Availability and Durability"},{"location":"associate/architect/s3/#types","text":"","title":"Types"},{"location":"associate/architect/s3/#standard-s3-default-type","text":"Highly available and durable. Data is stored redundantly across multiple devices in multiple facilities (>= 3 AZs) Designed for Frequent access! Suitable for most workloads","title":"Standard S3 (Default Type)"},{"location":"associate/architect/s3/#standard-infrequent-access","text":"99.9% Availability 99.99999999999% Durability (11 9's) Designed for infrequent accessed data Rapid Access Used for data that is accessed less frequently but requires rapid access when needed Pay to Access to Data This is a low per-GB storage price Has a per-GB retrieval fee Use cases Great for long-term storage, backups, and as a data store for disaster recovery files","title":"Standard-Infrequent Access"},{"location":"associate/architect/s3/#one-zone-infrequent-access","text":"99.5% Availability 99.99999999999% Durability (11 9's) Same as Standard-Infrequent Access but only in 1 AZ 20% less than S3 Standard-IA Great for long-lived, infrequently accessed, non-critical data","title":"One Zone-Infrequent Access"},{"location":"associate/architect/s3/#glacier","text":"99.99% Availability 99.99999999999% Durability (11 9's) Retrieval times that range from 1 minute to 12 hours. Historically should be data accessed a few times a year. Cheap Storage Optimized for data that is VERY infrequently access Primarily used for ARCHIVING Pay each time you access data","title":"Glacier"},{"location":"associate/architect/s3/#glacier-deep-archive","text":"99.99% Availability 99.99999999999% Durability (11 9's) Archive data that is RARELY accessed data with a default retrieval time of 12 hours","title":"Glacier Deep Archive"},{"location":"associate/architect/s3/#intelligent-tiering","text":"99.99% Availability 99.99999999999% Durability (11 9's) Automatically moves your data based on the amount of times you access data Optimizes cost for monthly fee.","title":"Intelligent-Tiering"},{"location":"associate/architect/s3/#storage-costs","text":"","title":"Storage Costs"},{"location":"associate/architect/s3/#lifecycle-management","text":"Defined rules to automatically transition objects to a cheaper storage tier or delete objects that are no longer required after a set period of time","title":"Lifecycle Management"},{"location":"associate/architect/s3/#versioning","text":"With versioning all versions of an object are stored and can be retrieved, including deleted objects","title":"Versioning"},{"location":"associate/architect/s3/#securing-data","text":"Server-Side Encryption Can set default encryption on a bucket to encrypt all new objects that are stored in a bucket Access Control Lists (ACLs) Define which AWS accounts or groups are granted access and type of access. You can attach a S3 ACLs to individual objects within a bucket Bucket Policies S3 bucket polices specify what actions are allowed or denied (allow a user Alice to PUT but not DELETE objects in the bucket) JSON policies","title":"Securing Data"},{"location":"associate/architect/s3/#acl-vs-bucket-policies","text":"Access Control lists are designed to be applied to individual object levels Bucket policies are designed to be applied to entire bucket","title":"ACL vs Bucket Policies"},{"location":"associate/architect/s3/#data-consistency","text":"Strong Read-After-Write consistency After a successful write of a new object (PUT) or overwrite of an existing object, any subsequent read request immediately recieves the latest version of the object Strong consistency for list operations, so after a write you can immediately perform a listing of objects in a bucket with all changes reflected.","title":"Data consistency"},{"location":"associate/architect/s3/#hosting-static-website-in-s3","text":"You can use S3 to host static websites. S3 is great for hosting static websites since S3 Scales on demand! Must provide all static files and give index.html location and can optionally provide (error.html) Must apply policy to make objects public","title":"Hosting Static Website In S3"},{"location":"associate/architect/s3/#versioning-objects-in-s3","text":"","title":"Versioning Objects in S3"},{"location":"associate/architect/s3/#what-is-versioning","text":"Allows us to have multiple versions in s3 bucket Advantages: Keep all versions of objects in s3 Once enabled cannot be disabled (only suspended) Supports MFA Lifecycle Rules Great for Backup Tools Deletion creates a delete marker and does not actually delete the file. In order to restore a file the delete marker must be deleted.","title":"What is versioning"},{"location":"associate/architect/s3/#s3-object-lock","text":"You can use s3 object lock to store objects using a Write Once Read Many (WORM) model. It can help prevent objects from being deleted or modified for a fixed amount of time or indefinitely You can use S3 object lock to meet regulatory requirements that require WORM storage, or add an extra layer of protection against objects changes and deletions","title":"S3 Object Lock"},{"location":"associate/architect/s3/#governance-mode","text":"In governance mode users cant overwrite or delete an object version or alter its lock settings unless they have special permissions. With governance mode you protect objects against being deleted by most users, but you still grant some users permission to alter the retention settings or delete the objects if necessary","title":"Governance Mode"},{"location":"associate/architect/s3/#compliance-mode-hardcore","text":"In compliance mode, a protected object version cant be overwritten or deleted by any user INCLUDING the root user in your AWS account. When an object is locked in compliance mode, its retention mode cant be changed and its retention period cant be shortened. Compliance mode ensures an object version cant be overwritten or deleted for the duration of the retention period.","title":"Compliance Mode (Hardcore)"},{"location":"associate/architect/s3/#retention-periods","text":"A retention period protects an object version for a fixed amount of time. When you place a retention period on an object version, Amazon S3 stores a timestamp in the object version's meta data to indicate when the retention period expires. After retention period expires, the object version can be overwritten or deleted unless you also placed a legal hold on the object version.","title":"Retention Periods"},{"location":"associate/architect/s3/#legal-holds","text":"S3 object lock also enables you to place a legal hold on an object version. Like a retention period a legal hold prevents an object version from being overwritten or deleted. However a legal hold does not have an associated retention period and remains in effect until removed. Legal holds can be freely placed and removed by any user who has the s3:PutObjectLegalHold permission.","title":"Legal Holds"},{"location":"associate/architect/s3/#glacier-vault-lock","text":"A way to apply a WORM model to the entire Glacier bucket","title":"Glacier Vault Lock"},{"location":"associate/architect/s3/#s3-encryption","text":"Encryption in Transit SSL/TLS HTTPS Encryption at Rest: Server Side Encryption SSE-S3: S3-managed keys, using AES 256-bit encryption SSE-KMS: AWS Key management service managed keys SSE-C: Customer provided keys Encryption at Rest: Client Side Encryption Encrypt files yourself before uploading files","title":"S3 Encryption"},{"location":"associate/architect/s3/#enforcing-server-side-encryption","text":"","title":"Enforcing Server-Side Encryption"},{"location":"associate/architect/s3/#console-server-side-encryption","text":"Select the encryption setting on your S3 bucket. The easiest way is just to checkbox the console","title":"Console Server-Side Encryption"},{"location":"associate/architect/s3/#bucket-policy-server-side-encryption","text":"Can enforce encryption using bucket policy To encrypt file at upload time use: x-amz-server-side-encryption If the file is to be encrypted at upload time this parameter will need ot be included in the request header Two Options: AES256 (SSE-S3 - S3 managed keys) aws:kms (SSE-KMS - KMS managed keys) When parameter is included in the header of the PUT request, it tells S3 to encrypt the object at the time of upload using a specified encryption method. So to enforce encryption with Bucket Policies deny any PUT requests that are missing the encryption parameter in the header.","title":"Bucket Policy Server-Side Encryption"},{"location":"associate/architect/s3/#s3-prefixes","text":"After our bucket name we can have folders such as BUCKET_NAME/folder1/subfolder1 BUCKET_NAME/folder2/subfolder1 BUCKET_NAME/folder3 Prefix is just the folder pwd and not the file key","title":"S3 Prefixes"},{"location":"associate/architect/s3/#s3-performance","text":"S3 has extremely low latency. You can get the first byte out of S3 within 100-200 milliseconds You can achieve a high number of requests: 3500 PUT/COPY/POST/DELETE and 5500 GET/HEAD requests per second, per prefix Thus the more prefixes we have in our bucket the more performant it can become","title":"S3 Performance"},{"location":"associate/architect/s3/#s3-limitation-when-using-kms","text":"If you are using SSE-KMS to encrypt your objects in S3 you must keep in mind the KMS limit which are Region specific Based on Region requests per second ranges from 5500, 10000, 30000 Uploading and downloading will count towards the KMS quota Currently you can NOT request a quota increase for KMS","title":"S3 Limitation When Using KMS"},{"location":"associate/architect/s3/#uploads","text":"Recommended for files over 100 MB and REQUIRED for files over 5 GB Parallelize uploads (increases efficiency) Breaks big file into smaller parts and combines them into S3","title":"Uploads"},{"location":"associate/architect/s3/#downloads","text":"Byte range fetches Parallelize downloads by specifying byte ranges If failure in download its only for specific byte range","title":"Downloads"},{"location":"associate/architect/s3/#backup-data-with-s3-replication","text":"Used to be called \"Cross Region Replication\" Allows us to replicate objects from one bucket to another Versioning must be turned on in both buckets Objects existing in bucket are NOT automatically replicated Once replication is turned on all subsequent updated objects will be replicated automatically Delete markers are not replicated by default","title":"Backup Data With S3 Replication"},{"location":"associate/architect/s3/#exam-tips","text":"S3 is a safe place to store your files The data is spread across multiple devices and facilities to ensure availability and durability Object Based (allows you to upload any file type) NOT for OS or DB storage Max File Size is 5TB Min File size is 0 bytes Unlimited Storage!! Will always be https://BUCKET_NAME.s3.REGION.amazonaws.com/KEY_NAME Successful CLI or API uploads should always generate 200 return code Key: Object Name Value: Data itself Version ID: Allows you to store multiple versions of same object Versioning is not enabled by default because it costs money to store extra copies of data so the user must choose to opt in Metadata: Data about data you are storing (content-type, last-modified) Buckets are private by default Both bucket and object must be public to use! Uploading objects to bucket using CLI or API should always return 200 status code Can serve Static content websites S3 scales on demand Versioning supports MFA to require 2 forms of authorization to delete an object To enforce WORM model use S3 Object Locks Compliance mode stops any user from deleting or modifying objects (even ROOT user) Governance mode stops MOST users from deleting or modifying objects Encryption in transit with (SSL/TLS and HTTPS) Encryption at Rest: SSE (SSE-S3, SSE-KMS, SSE-C) Enforcement of encryption can be done with a bucket policy With replication Delete markers are not replicated by default","title":"Exam tips"},{"location":"associate/architect/shared-responsibility/","text":"Shared Responsibility Model Will be critical for not only the architecture certificate, but also other certifications. Amazon Responsibility Reliability of the cloud Security of the datacenter Underlying networking Hypervisor Your responsibility Customer Data Platform Application Identity and Access management Client and Server side encryption Operating system configurations Application Configurations Exam Tips Ask \"Can I do this myself in the cloud?\" If Yes, you are likely responsible If Not, then most likely Amazon is responsible Encryption is shared responsibility","title":"Shared Responsibility"},{"location":"associate/architect/shared-responsibility/#shared-responsibility-model","text":"Will be critical for not only the architecture certificate, but also other certifications.","title":"Shared Responsibility Model"},{"location":"associate/architect/shared-responsibility/#amazon-responsibility","text":"Reliability of the cloud Security of the datacenter Underlying networking Hypervisor","title":"Amazon Responsibility"},{"location":"associate/architect/shared-responsibility/#your-responsibility","text":"Customer Data Platform Application Identity and Access management Client and Server side encryption Operating system configurations Application Configurations","title":"Your responsibility"},{"location":"associate/architect/shared-responsibility/#exam-tips","text":"Ask \"Can I do this myself in the cloud?\" If Yes, you are likely responsible If Not, then most likely Amazon is responsible Encryption is shared responsibility","title":"Exam Tips"},{"location":"associate/architect/storage/","text":"Storage Think of storage like a giant disk in th cloud, it is safe place to save your information Includes: S3 EBS EFS FSx Storage Gateway","title":"Storage"},{"location":"associate/architect/storage/#storage","text":"Think of storage like a giant disk in th cloud, it is safe place to save your information Includes: S3 EBS EFS FSx Storage Gateway","title":"Storage"},{"location":"associate/architect/well-architected/","text":"Well Architected Whitepapers Link To Whitepapers Recommend reading the white paper on Well-Architected Found HERE Pillars Of Well Architected Operational Excellence Focuses on running and monitoring systems to deliver business value and continually improving processes and procedures Security Focuses on protecting information and systems Reliability Focuses on ensuring a workload performs its intended function correctly and consistently when it is expected to Performance Efficiency Focuses on using IT and computing resources efficiently Cost Optimization Focuses on avoiding unnecessary costs","title":"Well Architected"},{"location":"associate/architect/well-architected/#well-architected","text":"","title":"Well Architected"},{"location":"associate/architect/well-architected/#whitepapers","text":"Link To Whitepapers Recommend reading the white paper on Well-Architected Found HERE","title":"Whitepapers"},{"location":"associate/architect/well-architected/#pillars-of-well-architected","text":"","title":"Pillars Of Well Architected"},{"location":"associate/architect/well-architected/#operational-excellence","text":"Focuses on running and monitoring systems to deliver business value and continually improving processes and procedures","title":"Operational Excellence"},{"location":"associate/architect/well-architected/#security","text":"Focuses on protecting information and systems","title":"Security"},{"location":"associate/architect/well-architected/#reliability","text":"Focuses on ensuring a workload performs its intended function correctly and consistently when it is expected to","title":"Reliability"},{"location":"associate/architect/well-architected/#performance-efficiency","text":"Focuses on using IT and computing resources efficiently","title":"Performance Efficiency"},{"location":"associate/architect/well-architected/#cost-optimization","text":"Focuses on avoiding unnecessary costs","title":"Cost Optimization"},{"location":"associate/developer/api-gateway/","text":"API Gateway What is an API An API is a an application programming interface Takes request does sends it somewhere, gets a response then returns response to whoever made the original request. Types of APIs REST APIs (REpresentational State Transfer) Uses JSON (typically) SOAP APIs (Simple Object Access Protocol) Uses XML Not very simple## Serverless Brief history Data Center --> IAAS --> PAAS --> Containers --> Serverless AWS released EC2 2006 (Birth Of IAAS) Azure releases Platform As A Service (PAAS) Then containers came about and gave lightweigh alternative to server Lambda was release and serverless computing was born No need to worry about anything but code Every Alexa command is just Lambda speaking back What is API Gateway Amazon API Gateway is a fully managed service that makes it easy for developers to publish, maintain, monitor, and secure APIs at any scale. Witha few clicks in the AWS Management Console you can create an API that acts as a front door for applications to access data, business logic, or functionality from your back-end services. These services can be: EC2 AWS Lambda Any Web Application What can API Gateway do Expose HTTPS endpoints to define a RESTful API Serverless-ly connect to services like lambda and Dynabmodb Send each API endpoint to different target Runs efficiently with low cost Scale effortlessly Track and control usage by API key Throttle requests to prevent attacks Connect to CloudWatch to log all request for monitoring Control multiple versions of API How to configure API Gateway Define API (container) Define Resources and nested Resources (URL Paths) For each resource: Select supported HTTP methods (verbs) Set security Choose target (such as EC2, Lambda, DynamoDB, etc.) Set request and response transformations Deploy API to a Stage Use API Gateway domain, by default Can use custom Domain Supports AWS Certificate Manager (FREE SSL/TLS certs!) If you bought Domain with Route53 API Caching You can enable API caching in Amazon API Gateway to cache your endpoint's response Reduce the number of calls made to your endpoint Improve the latency of the calls made to your endpoint and improve the latency of the requests to your API When enabled for a stage API Gateway caches responses from your endpoint for a specified time-to-live (TTL) period in seconds Then responds to the request by looking up the endpoint response from the cache instead of making a request to your endpoint Same Origin Policy concept in web application security model. Web browser will allow scripts contained in a web page to access data in second webpage ONLY if both web pages have the same origin. This is done to prevent Cross-Site Scripting (XSS) attacks Enforced by Web browsers Ignored by tools (Postman, Insomnia, Curl, etc.) Cross-Origin Resource Sharing (CORS) Way the server at the other end (not the client code in the browser) can relax the same-origin policy Cross-origin resource sharing (CORS) is a mechanism that allows restricted resources on a web page to be requested from another domain outside the domain from wich the first resource was served. Browser makes HTTP OPTIONS call for URL OPTIONS is an HTTP method like GET, PUT, and POST Server returns a response that says \"These other domains are approved to GET this URL\" Error - \"Origin policy cannot be read at the remote resource?\" This means you need to enable CORS on API Gateway Advanced API Gateway API Gateway import features allows you to import Swagger v2.0 definition files Can overwrite definitions Can merge definitions API Throttling By default is throttle to 10,000 requests per seconds Max number of concurrent requests is 5,000 If limits are reached you will get a 429 Too Many Requests status code Limits can be lifted but further charges will be incured API Gateway can be used as SOAP web service passthrough","title":"API Gateway"},{"location":"associate/developer/api-gateway/#api-gateway","text":"","title":"API Gateway"},{"location":"associate/developer/api-gateway/#what-is-an-api","text":"An API is a an application programming interface Takes request does sends it somewhere, gets a response then returns response to whoever made the original request.","title":"What is an API"},{"location":"associate/developer/api-gateway/#types-of-apis","text":"REST APIs (REpresentational State Transfer) Uses JSON (typically) SOAP APIs (Simple Object Access Protocol) Uses XML Not very simple## Serverless Brief history Data Center --> IAAS --> PAAS --> Containers --> Serverless AWS released EC2 2006 (Birth Of IAAS) Azure releases Platform As A Service (PAAS) Then containers came about and gave lightweigh alternative to server Lambda was release and serverless computing was born No need to worry about anything but code Every Alexa command is just Lambda speaking back","title":"Types of APIs"},{"location":"associate/developer/api-gateway/#what-is-api-gateway","text":"Amazon API Gateway is a fully managed service that makes it easy for developers to publish, maintain, monitor, and secure APIs at any scale. Witha few clicks in the AWS Management Console you can create an API that acts as a front door for applications to access data, business logic, or functionality from your back-end services. These services can be: EC2 AWS Lambda Any Web Application What can API Gateway do Expose HTTPS endpoints to define a RESTful API Serverless-ly connect to services like lambda and Dynabmodb Send each API endpoint to different target Runs efficiently with low cost Scale effortlessly Track and control usage by API key Throttle requests to prevent attacks Connect to CloudWatch to log all request for monitoring Control multiple versions of API How to configure API Gateway Define API (container) Define Resources and nested Resources (URL Paths) For each resource: Select supported HTTP methods (verbs) Set security Choose target (such as EC2, Lambda, DynamoDB, etc.) Set request and response transformations Deploy API to a Stage Use API Gateway domain, by default Can use custom Domain Supports AWS Certificate Manager (FREE SSL/TLS certs!) If you bought Domain with Route53","title":"What is API Gateway"},{"location":"associate/developer/api-gateway/#api-caching","text":"You can enable API caching in Amazon API Gateway to cache your endpoint's response Reduce the number of calls made to your endpoint Improve the latency of the calls made to your endpoint and improve the latency of the requests to your API When enabled for a stage API Gateway caches responses from your endpoint for a specified time-to-live (TTL) period in seconds Then responds to the request by looking up the endpoint response from the cache instead of making a request to your endpoint","title":"API Caching"},{"location":"associate/developer/api-gateway/#same-origin-policy","text":"concept in web application security model. Web browser will allow scripts contained in a web page to access data in second webpage ONLY if both web pages have the same origin. This is done to prevent Cross-Site Scripting (XSS) attacks Enforced by Web browsers Ignored by tools (Postman, Insomnia, Curl, etc.)","title":"Same Origin Policy"},{"location":"associate/developer/api-gateway/#cross-origin-resource-sharing-cors","text":"Way the server at the other end (not the client code in the browser) can relax the same-origin policy Cross-origin resource sharing (CORS) is a mechanism that allows restricted resources on a web page to be requested from another domain outside the domain from wich the first resource was served. Browser makes HTTP OPTIONS call for URL OPTIONS is an HTTP method like GET, PUT, and POST Server returns a response that says \"These other domains are approved to GET this URL\" Error - \"Origin policy cannot be read at the remote resource?\" This means you need to enable CORS on API Gateway","title":"Cross-Origin Resource Sharing (CORS)"},{"location":"associate/developer/api-gateway/#advanced-api-gateway","text":"API Gateway import features allows you to import Swagger v2.0 definition files Can overwrite definitions Can merge definitions API Throttling By default is throttle to 10,000 requests per seconds Max number of concurrent requests is 5,000 If limits are reached you will get a 429 Too Many Requests status code Limits can be lifted but further charges will be incured API Gateway can be used as SOAP web service passthrough","title":"Advanced API Gateway"},{"location":"associate/developer/cloudfront/","text":"CloudFront Content Delivery Network (CDN) A system of distributed servers (network) that deliver webpages and other web content to a user based on geographic locations of the user, the origin of the webpage, and a content deliver server Basically speeds up delivery of web content Content Delivery vs. Transfer Acceleration CDN focus on download Transfer Acceleration is upload Scenario Website in UK Users in America, South America, South Africa, Austrailia, India Users further from UK can experience greater latency and less responsiveness We use edge locations to keep copy of website in edge locations which are much closer to users. First time user requests resource edge location makes request to server in UK and downloads the resource resource is then cached so that subsequent requests for that item will be served to user from edge location cache is temporary and will be cleared after a time period cache can be cleared manually but there will be a fee to do so This may be done if you need users to be given most recent updates Key Terminology Edge Location Location where content is cached and can also be written (Not a region or AZ) More edge locations than AZs or Regions (edge locations > AZs > Regions) Origin The origin of all the files that the CDN will be distributing Can be S3 Bucket, EC2 Instance, Elastic Load Balancer, or Route53 Distribution The name given to CDN which consist of collection of edge locations Web Distribution Typically used for websites RTMP Used for Media Streaming Cloud Front can be used to deliver the ENTIRE website including the following content dynamic static streaming interactive Can be used with NON AWS servers Distribution Types Web Distribution Used for Websites, HTTP/HTTPS Can NOT serve Adobe flash mutli media content RTMP Distribution (Adobe Real Time Messaging Protocol) Media streaming Flash multi-media content CloudFront can be used for Transfer Acceleration for uploading files to S3 You can restrict access to certain (paying usings) by using signed URL or signed cookies Can use WAF to protect at application layer Can use whitelist and blacklist to restrict access to countries Cache can be cleared by invalidating objects (which you will be charged for) CloudFront can be used to upload files as well as download files.","title":"CouldFront"},{"location":"associate/developer/cloudfront/#cloudfront","text":"","title":"CloudFront"},{"location":"associate/developer/cloudfront/#content-delivery-network-cdn","text":"A system of distributed servers (network) that deliver webpages and other web content to a user based on geographic locations of the user, the origin of the webpage, and a content deliver server Basically speeds up delivery of web content Content Delivery vs. Transfer Acceleration CDN focus on download Transfer Acceleration is upload Scenario Website in UK Users in America, South America, South Africa, Austrailia, India Users further from UK can experience greater latency and less responsiveness We use edge locations to keep copy of website in edge locations which are much closer to users. First time user requests resource edge location makes request to server in UK and downloads the resource resource is then cached so that subsequent requests for that item will be served to user from edge location cache is temporary and will be cleared after a time period cache can be cleared manually but there will be a fee to do so This may be done if you need users to be given most recent updates Key Terminology Edge Location Location where content is cached and can also be written (Not a region or AZ) More edge locations than AZs or Regions (edge locations > AZs > Regions) Origin The origin of all the files that the CDN will be distributing Can be S3 Bucket, EC2 Instance, Elastic Load Balancer, or Route53 Distribution The name given to CDN which consist of collection of edge locations Web Distribution Typically used for websites RTMP Used for Media Streaming Cloud Front can be used to deliver the ENTIRE website including the following content dynamic static streaming interactive Can be used with NON AWS servers Distribution Types Web Distribution Used for Websites, HTTP/HTTPS Can NOT serve Adobe flash mutli media content RTMP Distribution (Adobe Real Time Messaging Protocol) Media streaming Flash multi-media content CloudFront can be used for Transfer Acceleration for uploading files to S3 You can restrict access to certain (paying usings) by using signed URL or signed cookies Can use WAF to protect at application layer Can use whitelist and blacklist to restrict access to countries Cache can be cleared by invalidating objects (which you will be charged for) CloudFront can be used to upload files as well as download files.","title":"Content Delivery Network (CDN)"},{"location":"associate/developer/dynamodb/","text":"Dynamodb Dynamodb is a fast and flexible NoSQL Designed for apps that need single-digit millisecond latency at any scale Full managed databse that supports both document and key-value data models Has flexible data model and reliable performance Great fit for mobile, web, gaming, ad-tech, IoT applicaitons Dynamodb is serverless and scalable Backed by SSD Storage Spread accross 3 geographically distinc data centers Choice of 2 consitency models: Eventual consistent Reads (Default) Consistency across all copies of data that is usually reached within a second Strongly consistent Reads Returns a result that reflects all writes that received a successful response prior to the read Dynamodb make up: Tables Items (think row in table) Attribute (Think Column of table) Key (identifier for data) Value (actual data) Documents can be written in JSON, HTML, XML Dynamodb Primary Keys Dynamodb stores and retrieves data based on Primary Key Two types of primary keys Partition Key Unique attribute (example user ID) Value of partition key is input to internal hash function which determines the partion or physical location on which the data is stored If using partition key as your primary key, then no two items can have the same partition key Composite Key (Partition Key + Sort Key) in combination. Same user posting mutiple times in forum Primary key would be COmposite Key consisting of: Partition Key - User ID Sort key - Timestamp of the post 2 items may have the same partition key but they must have a different Sort key All items with same Partition Key are stored together, then sorted according to the sort key value Allows you to store multiple items with the same Partition Key Dynamodb Access Control Authentication and Access Control managed using AWS IAM Create an IAM user within your AWS accoun which has specific permissions to access and create DynamoDB tables Create IAM role which can enable you to obtain temporary access keys Can create special IAM condition to restrict user access to only their records. Exam Tips Low latency Supports both document and key value data models JSON, HTML, XML 2 types of primary key Partion key Composite Key (Partition + Sort Keys) Consistency models Strongly Consitent Eventually Consistent Indexies 2 types of indexes supported to help speed up queries Local Secondary Index Can only be created when creating table Cannot be added or modified later Has same partition key as table Has different sort key than table ANy queries based on this sort Key are much faster than using the index than the main table Global Secondary Index Much more flexible Create index whenever you like Choose different partion key and sort key to original table Speeds up any queries relating to this alternative partion and sort key Indexies Exam Tips Indexies enable faster queries on data Gives different view of your data based on alternative Partion / Sort keys Differences in 2 indexies Local created at table creation. Same partion different sort Global secondary created whenever and has different partion and different sort keys Dynamodb Scan vs Query API Calls Query A query is operation that finds items in your table based on primary key attribute and distinct value to search for If looking for user with ID of 212 then you would query based off primary user ID and value 212 This will select all attributes for document Can use optional sort key name and value to refine results By default query returns all attributes for item ProjectionExpression parameter will allow you to specify what attributes should be return Results always sorted by sort key Numeric order by default in ascending order (1,2,3,4) Can reverse order by setting ScanIndexForward (Tricky because this is for Query not SCAN!) paramerte to false By default Queries are eventually consistent Can be explicitly set for Stongly consistent Scan A scan operation examines ever item in the table By default returns all data attributes Can also use ProjectionExpression parameter to set what attributes to return Can filter results of scan after they have been run Query Or Scan Query is more efficient than Scan Scan dumps the entire table then filters out the values to provide Scans take longer the larger the table gets Scan operation on a large table can use up the provisioned throughput for a table in just one single operation You can reduce impact of query or scan by setting smaller page size could set page size to 40 larger number of operations with smaller size each Avoid using scan operations if you can design tables in a way that you can use the query, GET, or BatchGetItem APIs By default scan operation processes data sequentially then returns in 1 MB incements only scans one partition at a time Can configure scan to run in parrallel if you divide a table or index into segments Scan and Query exam tips Query operation finds items in table using only the primary key attribute You provide the primary key name and distinct value to search Scan operation examines every item in the table Both return all data attributes by default Use ProjectionExpression parameter to refine results Query results alwasy sorted by Sort key Sorted in ascending order Set ScanIndexForward parameter to false to reverser the order (QUERIES ONLY) Query operation is generally more efficient than scan Reduce page size to make scan more efficient Can make parrallel scan Design tables to use query, GET, or BatchGetItem APIs DynamoDb Provisioned Throughput Throughput measured in capacity Units Two Types of Capacity Units Write Capacity Unit 1 x Write Capacity Unit = 1 x 1KB Write per second Read Capacity Unit 1 x Read Capacity Unit = 1 x Strongly Consistent Read of 4KB per second OR 2 x Eventually Consistent Reads of 4KB per second (DEFAULT) If application reads or writes large objects it will cost more Provisioned Throughput Exam Tips Provisioned throughput is measured in capacity units 1 x Write Capacity = 1 x 1KB Write per second 1 x Read Capacity Unit = 1 x Strongly Consistent Read of 4KB per second OR 2 x Eventually Consistent Reads of 4KB per second (DEFAULT) When Calculating take number of reads or writes a second multiply that by the size per operation / the per second of operation rounded up. DynamoDB OnDemand Capacity New Pricing option Chareges apply for Reading, Writing, and Storing data Do not need to specify Read and Write capacity Will scale up and down based on read and writes to your database Ideal for unpredictable workloads Allows you to pay for only what you use (pay per request) DynamoDB Accelerator (DAX) Fully managed clustered in-memory cache for DynamoDB ONLY FOR READ operations Delivers up to 10x read performance Microsecond performance for millions of requests per second Ideal for Read-Heavy and bursty workloads How does it work DAX is write-through caching service When data is written to dynamodb it is also written to DAX Point Dynamodb API Calls to DAX cluster If item is in DAX it will be returned from DAX If item does not exist then DAX will retrieve item from DynamoDB and write it in cache for further requests Allows ability to reduce Provisioned Read Capacity Not GOOD for Caters ONLY for Eventually consitent reads CANNOT do Strongly Consitent Write intensive Applications that do not perform many read operations Applications that dont require microsecond response times Elasticache with DynamoDB In memory caching that sits infront of many RDS databases This can also sit infront of Dynamodb Sits between application and database Takes load off database good if your database is particularly read-heavy and the data is not changing frequently Supports Memcached and Redis 2 Stategies available Lazy Loading Loads data into cache only when necessary if requested data is in cache Elasticache returns data to application If not in cache or has expired Elasticache returns a null Application then fetches data from the database and writes the data recieved into cache so that is available next time Advantages: Only requested data cached Node failures are not fatal Disadvantages: Cache miss penalty (initial request query to database and write data after done) Stale data - if data is only updated when cache is updated it can become out of date and does not automatically update Time To Live (TTL) How to deal with stale data Sets a number of seconds until data expires Hits on expired data will be treated as miss Write-Through adds or updates data to cache whenever data is written to database Advantages: Data is never stale Users are generally more tolerant of additional latency when updating data than when retrieving it Disadvantages Does invoke write penalty for having to write twice If node fails and new one is spun up data is missing until added or updated This can be mitigated by implementing lazy loading in conjucture with write-through) Wasted resources if most of data is never read DAX vs Elasticache DAX optimized just for DynamoDB DAX ONLY supports Write-Through If you need lazy loading you have to use Elasticache DynamoDB Transactions DynamoDB Transactions were designed for mission critical operations Transactions ACID Transactions (Atomic, Consitent, Isolated, Durable) Read or write multiple items across multiple tables as an all or nothing operation Check for a pre-requisite condition before writing to a table Implement complex business logic into single atomic transaction DynamoDB TTL DynamoDB Time To Live (TTL) Time To Live is attribute that defines an expiry time for your data Expired items marked for deletion If data is marked it will be deleted with in 48 hours Good for removing irrelevant or old data Session data Event Logs Temporary data Reduce cost by removing data no longer relevant TTL is expressed as epoch/unix time numeric value represents the number of seconds that have elapsed since 12am January 1 1970 When current time is greater than TTL the item will become expired and marked for deletion You can filter out expired items from your queries and scans This is useful because deletes can take 48 hours DynamoDB Streams Streams are Time-ordered sequence of itme level modifications (insert, update, delete) Logs are encrypted at rest and stored for 24 hours Accessed using a dedicated endpoint By default the Primary key is recorded Before and After images can be captured Used for triggers Accessed through their own endpoints Events are recorded in near real time Really good for serverless and lambda Application can take actions based on content Lambda can pull stream and trigger events based on stream events Provisioned Throughput Exceeded Exception Will see this if your request read/write capacity provisioned is exceeded for DynamoDB table SDK will autoretry until successful If not using SDK Reduce request frequency Implement Exponetial backoff Exponential Backoff Components in network can generate errors due to being overloaded Usally dealt with by implementing retries (which SDK does) In addition to reties SDK also uses exponential Backoff Progressively longer waits between consecutive retries (50 ms, 100 ms, 200ms) if after 1 minute does not work, your request size may be exceeding the throughput for read/write capacity Exponential backoff is used for more than Dynamodb. Every feature of AWS SDK. Applies to many services in AWS S3 CloudFormation SES If not using SDK will need to implement this yourself in the application","title":"DynamoDB"},{"location":"associate/developer/dynamodb/#dynamodb","text":"Dynamodb is a fast and flexible NoSQL Designed for apps that need single-digit millisecond latency at any scale Full managed databse that supports both document and key-value data models Has flexible data model and reliable performance Great fit for mobile, web, gaming, ad-tech, IoT applicaitons Dynamodb is serverless and scalable Backed by SSD Storage Spread accross 3 geographically distinc data centers Choice of 2 consitency models: Eventual consistent Reads (Default) Consistency across all copies of data that is usually reached within a second Strongly consistent Reads Returns a result that reflects all writes that received a successful response prior to the read Dynamodb make up: Tables Items (think row in table) Attribute (Think Column of table) Key (identifier for data) Value (actual data) Documents can be written in JSON, HTML, XML","title":"Dynamodb"},{"location":"associate/developer/dynamodb/#dynamodb-primary-keys","text":"Dynamodb stores and retrieves data based on Primary Key Two types of primary keys Partition Key Unique attribute (example user ID) Value of partition key is input to internal hash function which determines the partion or physical location on which the data is stored If using partition key as your primary key, then no two items can have the same partition key Composite Key (Partition Key + Sort Key) in combination. Same user posting mutiple times in forum Primary key would be COmposite Key consisting of: Partition Key - User ID Sort key - Timestamp of the post 2 items may have the same partition key but they must have a different Sort key All items with same Partition Key are stored together, then sorted according to the sort key value Allows you to store multiple items with the same Partition Key","title":"Dynamodb Primary Keys"},{"location":"associate/developer/dynamodb/#dynamodb-access-control","text":"Authentication and Access Control managed using AWS IAM Create an IAM user within your AWS accoun which has specific permissions to access and create DynamoDB tables Create IAM role which can enable you to obtain temporary access keys Can create special IAM condition to restrict user access to only their records.","title":"Dynamodb Access Control"},{"location":"associate/developer/dynamodb/#exam-tips","text":"Low latency Supports both document and key value data models JSON, HTML, XML 2 types of primary key Partion key Composite Key (Partition + Sort Keys) Consistency models Strongly Consitent Eventually Consistent","title":"Exam Tips"},{"location":"associate/developer/dynamodb/#indexies","text":"2 types of indexes supported to help speed up queries Local Secondary Index Can only be created when creating table Cannot be added or modified later Has same partition key as table Has different sort key than table ANy queries based on this sort Key are much faster than using the index than the main table Global Secondary Index Much more flexible Create index whenever you like Choose different partion key and sort key to original table Speeds up any queries relating to this alternative partion and sort key","title":"Indexies"},{"location":"associate/developer/dynamodb/#indexies-exam-tips","text":"Indexies enable faster queries on data Gives different view of your data based on alternative Partion / Sort keys Differences in 2 indexies Local created at table creation. Same partion different sort Global secondary created whenever and has different partion and different sort keys","title":"Indexies Exam Tips"},{"location":"associate/developer/dynamodb/#dynamodb-scan-vs-query-api-calls","text":"","title":"Dynamodb Scan vs Query API Calls"},{"location":"associate/developer/dynamodb/#query","text":"A query is operation that finds items in your table based on primary key attribute and distinct value to search for If looking for user with ID of 212 then you would query based off primary user ID and value 212 This will select all attributes for document Can use optional sort key name and value to refine results By default query returns all attributes for item ProjectionExpression parameter will allow you to specify what attributes should be return Results always sorted by sort key Numeric order by default in ascending order (1,2,3,4) Can reverse order by setting ScanIndexForward (Tricky because this is for Query not SCAN!) paramerte to false By default Queries are eventually consistent Can be explicitly set for Stongly consistent","title":"Query"},{"location":"associate/developer/dynamodb/#scan","text":"A scan operation examines ever item in the table By default returns all data attributes Can also use ProjectionExpression parameter to set what attributes to return Can filter results of scan after they have been run","title":"Scan"},{"location":"associate/developer/dynamodb/#query-or-scan","text":"Query is more efficient than Scan Scan dumps the entire table then filters out the values to provide Scans take longer the larger the table gets Scan operation on a large table can use up the provisioned throughput for a table in just one single operation You can reduce impact of query or scan by setting smaller page size could set page size to 40 larger number of operations with smaller size each Avoid using scan operations if you can design tables in a way that you can use the query, GET, or BatchGetItem APIs By default scan operation processes data sequentially then returns in 1 MB incements only scans one partition at a time Can configure scan to run in parrallel if you divide a table or index into segments","title":"Query Or Scan"},{"location":"associate/developer/dynamodb/#scan-and-query-exam-tips","text":"Query operation finds items in table using only the primary key attribute You provide the primary key name and distinct value to search Scan operation examines every item in the table Both return all data attributes by default Use ProjectionExpression parameter to refine results Query results alwasy sorted by Sort key Sorted in ascending order Set ScanIndexForward parameter to false to reverser the order (QUERIES ONLY) Query operation is generally more efficient than scan Reduce page size to make scan more efficient Can make parrallel scan Design tables to use query, GET, or BatchGetItem APIs","title":"Scan and Query exam tips"},{"location":"associate/developer/dynamodb/#dynamodb-provisioned-throughput","text":"Throughput measured in capacity Units Two Types of Capacity Units Write Capacity Unit 1 x Write Capacity Unit = 1 x 1KB Write per second Read Capacity Unit 1 x Read Capacity Unit = 1 x Strongly Consistent Read of 4KB per second OR 2 x Eventually Consistent Reads of 4KB per second (DEFAULT) If application reads or writes large objects it will cost more","title":"DynamoDb Provisioned Throughput"},{"location":"associate/developer/dynamodb/#provisioned-throughput-exam-tips","text":"Provisioned throughput is measured in capacity units 1 x Write Capacity = 1 x 1KB Write per second 1 x Read Capacity Unit = 1 x Strongly Consistent Read of 4KB per second OR 2 x Eventually Consistent Reads of 4KB per second (DEFAULT) When Calculating take number of reads or writes a second multiply that by the size per operation / the per second of operation rounded up.","title":"Provisioned Throughput Exam Tips"},{"location":"associate/developer/dynamodb/#dynamodb-ondemand-capacity","text":"New Pricing option Chareges apply for Reading, Writing, and Storing data Do not need to specify Read and Write capacity Will scale up and down based on read and writes to your database Ideal for unpredictable workloads Allows you to pay for only what you use (pay per request)","title":"DynamoDB OnDemand Capacity"},{"location":"associate/developer/dynamodb/#dynamodb-accelerator-dax","text":"Fully managed clustered in-memory cache for DynamoDB ONLY FOR READ operations Delivers up to 10x read performance Microsecond performance for millions of requests per second Ideal for Read-Heavy and bursty workloads How does it work DAX is write-through caching service When data is written to dynamodb it is also written to DAX Point Dynamodb API Calls to DAX cluster If item is in DAX it will be returned from DAX If item does not exist then DAX will retrieve item from DynamoDB and write it in cache for further requests Allows ability to reduce Provisioned Read Capacity Not GOOD for Caters ONLY for Eventually consitent reads CANNOT do Strongly Consitent Write intensive Applications that do not perform many read operations Applications that dont require microsecond response times","title":"DynamoDB Accelerator (DAX)"},{"location":"associate/developer/dynamodb/#elasticache-with-dynamodb","text":"In memory caching that sits infront of many RDS databases This can also sit infront of Dynamodb Sits between application and database Takes load off database good if your database is particularly read-heavy and the data is not changing frequently Supports Memcached and Redis 2 Stategies available Lazy Loading Loads data into cache only when necessary if requested data is in cache Elasticache returns data to application If not in cache or has expired Elasticache returns a null Application then fetches data from the database and writes the data recieved into cache so that is available next time Advantages: Only requested data cached Node failures are not fatal Disadvantages: Cache miss penalty (initial request query to database and write data after done) Stale data - if data is only updated when cache is updated it can become out of date and does not automatically update Time To Live (TTL) How to deal with stale data Sets a number of seconds until data expires Hits on expired data will be treated as miss Write-Through adds or updates data to cache whenever data is written to database Advantages: Data is never stale Users are generally more tolerant of additional latency when updating data than when retrieving it Disadvantages Does invoke write penalty for having to write twice If node fails and new one is spun up data is missing until added or updated This can be mitigated by implementing lazy loading in conjucture with write-through) Wasted resources if most of data is never read","title":"Elasticache with DynamoDB"},{"location":"associate/developer/dynamodb/#dax-vs-elasticache","text":"DAX optimized just for DynamoDB DAX ONLY supports Write-Through If you need lazy loading you have to use Elasticache","title":"DAX vs Elasticache"},{"location":"associate/developer/dynamodb/#dynamodb-transactions","text":"DynamoDB Transactions were designed for mission critical operations Transactions ACID Transactions (Atomic, Consitent, Isolated, Durable) Read or write multiple items across multiple tables as an all or nothing operation Check for a pre-requisite condition before writing to a table Implement complex business logic into single atomic transaction","title":"DynamoDB Transactions"},{"location":"associate/developer/dynamodb/#dynamodb-ttl","text":"DynamoDB Time To Live (TTL) Time To Live is attribute that defines an expiry time for your data Expired items marked for deletion If data is marked it will be deleted with in 48 hours Good for removing irrelevant or old data Session data Event Logs Temporary data Reduce cost by removing data no longer relevant TTL is expressed as epoch/unix time numeric value represents the number of seconds that have elapsed since 12am January 1 1970 When current time is greater than TTL the item will become expired and marked for deletion You can filter out expired items from your queries and scans This is useful because deletes can take 48 hours","title":"DynamoDB TTL"},{"location":"associate/developer/dynamodb/#dynamodb-streams","text":"Streams are Time-ordered sequence of itme level modifications (insert, update, delete) Logs are encrypted at rest and stored for 24 hours Accessed using a dedicated endpoint By default the Primary key is recorded Before and After images can be captured Used for triggers Accessed through their own endpoints Events are recorded in near real time Really good for serverless and lambda Application can take actions based on content Lambda can pull stream and trigger events based on stream events","title":"DynamoDB Streams"},{"location":"associate/developer/dynamodb/#provisioned-throughput-exceeded-exception","text":"Will see this if your request read/write capacity provisioned is exceeded for DynamoDB table SDK will autoretry until successful If not using SDK Reduce request frequency Implement Exponetial backoff","title":"Provisioned Throughput Exceeded Exception"},{"location":"associate/developer/dynamodb/#exponential-backoff","text":"Components in network can generate errors due to being overloaded Usally dealt with by implementing retries (which SDK does) In addition to reties SDK also uses exponential Backoff Progressively longer waits between consecutive retries (50 ms, 100 ms, 200ms) if after 1 minute does not work, your request size may be exceeding the throughput for read/write capacity Exponential backoff is used for more than Dynamodb. Every feature of AWS SDK. Applies to many services in AWS S3 CloudFormation SES If not using SDK will need to implement this yourself in the application","title":"Exponential Backoff"},{"location":"associate/developer/ebs/","text":"EBS Volumes Elastic Block Store Storage volumes that can be attached to EC2 instances Can be used to: Create file system Run a database Run Operating System Store Data Install Applications Designed for mission critical Production Workloads Automatically replicated within single AZ to protect against failure (this is automatic) Scalable (Dynamically increase capacity and change the type with 0 downtime) TYPES: I/O operations Per Second (IOPS) SDD: General Purpose SSD (gp2) 3 IOPS per GiB up to 13,000 IOPS per volume Good for boot volumes and test applications Provisioned IOPS SSD (io1) High performance option and expensive Up to 64,000 IOPS per volume 50 IOPS per GiB Use if you need more than 16,000 IOPS Designed for I/O intensive applications Provisioned IOPS SSD (io2) Latest generation Higher Durability and more IOPS per GiB SAME max IOPS Same price as io2 500 IOPS per GiB 99.999% durability HDD: Throughput Optimized HDD (st1) CANNOT BE BOOT Low-cost HDD volume Store LOADS of data Throughput of 40 MB/s per TB Ability to burst 250 BM/s per TB Max throughput of 500 MB/s per volume Big Data, Data warehouses, ETL, and log processing Cold HDD (SC1) Lowest Cost Option EBS volume types https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html EBS instances created from snapshots will maintain encryption status Encrypted - > Encrypted Un-encrypted -> Un-encrypted IOPS Measures number of read and write operations per seconds Important metric for quick transactions, low latency apps, transaction workloads The ability to action reads and writes very quick Throughput Measures number of bits read or written per seconds Important metric for large datasets, large I/O sizes, complex queries All about ability to deal with large datasets.","title":"EBS"},{"location":"associate/developer/ebs/#ebs-volumes","text":"Elastic Block Store Storage volumes that can be attached to EC2 instances Can be used to: Create file system Run a database Run Operating System Store Data Install Applications Designed for mission critical Production Workloads Automatically replicated within single AZ to protect against failure (this is automatic) Scalable (Dynamically increase capacity and change the type with 0 downtime) TYPES: I/O operations Per Second (IOPS) SDD: General Purpose SSD (gp2) 3 IOPS per GiB up to 13,000 IOPS per volume Good for boot volumes and test applications Provisioned IOPS SSD (io1) High performance option and expensive Up to 64,000 IOPS per volume 50 IOPS per GiB Use if you need more than 16,000 IOPS Designed for I/O intensive applications Provisioned IOPS SSD (io2) Latest generation Higher Durability and more IOPS per GiB SAME max IOPS Same price as io2 500 IOPS per GiB 99.999% durability HDD: Throughput Optimized HDD (st1) CANNOT BE BOOT Low-cost HDD volume Store LOADS of data Throughput of 40 MB/s per TB Ability to burst 250 BM/s per TB Max throughput of 500 MB/s per volume Big Data, Data warehouses, ETL, and log processing Cold HDD (SC1) Lowest Cost Option EBS volume types https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html EBS instances created from snapshots will maintain encryption status Encrypted - > Encrypted Un-encrypted -> Un-encrypted","title":"EBS Volumes"},{"location":"associate/developer/ebs/#iops","text":"Measures number of read and write operations per seconds Important metric for quick transactions, low latency apps, transaction workloads The ability to action reads and writes very quick Throughput Measures number of bits read or written per seconds Important metric for large datasets, large I/O sizes, complex queries All about ability to deal with large datasets.","title":"IOPS"},{"location":"associate/developer/ec2/","text":"EC2 Elastic Compute Cloud (EC2) Secure, resizable compute capacity in the Cloud Basically VM hosted in AWS Designed to make web scale cloud computing easier Capacity when you need it and complete control History: Game Changer when it was introduced. Pay only what you use No Wasted Capacity (Grow and Shrink when needed) Prior to EC2 (Capacity Estimates, Long term investment, 3-5 years) Servers Running in Minutes NOT Months. Pricing Models: On Demand (Pay For Time Running) Flexible Short-Term Testing The Water. Reserved Instances (Reserve capacity for 1-3 years BIG discount. Up to 72%) Predictable Usage (steady state) Specific Capacity Requirements Pay Up-Front Standard RIs (Claim 72% off) Cannot Change Instance Size Later Convertible RIs Up to 54% off. Option to convert to other instance type of equal or greater value Scheduled RIs Launch within time window you define Match capacity reservation time frame Use RIs during your busy time Spot (Purchase unused capacity at discount of 90% Prices. Process can be interrupted) Applications that have flexible start and end times Applications that are feasible at very low compute prices Users with an urgent need for large amounts of additional computing capacity Dedicated (Physical EC2 server dedicated for your use. Good for software license restriction. Also most expensive) Application with Compliance requirement that does not support multi-tenant virtualization Purchase Plans: On-Demand Reserved Saving Plans: Save up to 72% when paying for All AWS Compute usage, regardless of instance type or Region Commit To One or Three Years Super Flexible (Not only for EC2) EC2 Instance Types: Stats of Instance Type Hardware Capabilities CPU Memory Storage Instance Types are optimized to fit different use cases Acryonym To Remember Types FIGHT DR MCPXZ F - For FPGA I - FOR IOPS G - Graphics H - High Disk Throughput T - Cheap general purpose D - For Density R - For RAM M - Main choice for general purpose apps C - For Compute P - Graphics X - Extreme Memory Z - Extreme memory and CPU","title":"EC2"},{"location":"associate/developer/ec2/#ec2","text":"Elastic Compute Cloud (EC2) Secure, resizable compute capacity in the Cloud Basically VM hosted in AWS Designed to make web scale cloud computing easier Capacity when you need it and complete control History: Game Changer when it was introduced. Pay only what you use No Wasted Capacity (Grow and Shrink when needed) Prior to EC2 (Capacity Estimates, Long term investment, 3-5 years) Servers Running in Minutes NOT Months. Pricing Models: On Demand (Pay For Time Running) Flexible Short-Term Testing The Water. Reserved Instances (Reserve capacity for 1-3 years BIG discount. Up to 72%) Predictable Usage (steady state) Specific Capacity Requirements Pay Up-Front Standard RIs (Claim 72% off) Cannot Change Instance Size Later Convertible RIs Up to 54% off. Option to convert to other instance type of equal or greater value Scheduled RIs Launch within time window you define Match capacity reservation time frame Use RIs during your busy time Spot (Purchase unused capacity at discount of 90% Prices. Process can be interrupted) Applications that have flexible start and end times Applications that are feasible at very low compute prices Users with an urgent need for large amounts of additional computing capacity Dedicated (Physical EC2 server dedicated for your use. Good for software license restriction. Also most expensive) Application with Compliance requirement that does not support multi-tenant virtualization Purchase Plans: On-Demand Reserved Saving Plans: Save up to 72% when paying for All AWS Compute usage, regardless of instance type or Region Commit To One or Three Years Super Flexible (Not only for EC2) EC2 Instance Types: Stats of Instance Type Hardware Capabilities CPU Memory Storage Instance Types are optimized to fit different use cases Acryonym To Remember Types FIGHT DR MCPXZ F - For FPGA I - FOR IOPS G - Graphics H - High Disk Throughput T - Cheap general purpose D - For Density R - For RAM M - Main choice for general purpose apps C - For Compute P - Graphics X - Extreme Memory Z - Extreme memory and CPU","title":"EC2"},{"location":"associate/developer/elb/","text":"Elastic Load Balancers Balances loads between multiple web servers Types: Application Load Balancer Application layer 7 OSI \u00e2\u20ac\u0153Smart Decisions\u00e2\u20ac\u009d Can see what request is doing to determine what needs done with request Can create advanced request routing Best suited for load balancing of HTTP and HTTPS Network Load Balancer Layer 4 Super Fast performance Best suited for TCP traffic Capable of handling millions of requests per seconds Use for extreme performance Most expensive Classic Load Balancer Not Recommended Legacy Purposes Tested on exam alot Meant for Legacy HTTP/HTTPS Sticky Sessions and X-Forwarded Can do layer 7 or layer 4 Load Balancer Errors: Error 504 Gateway has timed out if your application stops with 504 that means the application is having issues. This could be either at Web Server layer or at Database Layer. X-Forwarded-For Header: User (123.45.6.789) -> Load balancer (10.0.0.23) -> EC2 (10.0.0.23) The user sends a request to load balancer, load balancer does not use the user's public IP it hits the private IP for EC2 and the EC2 sees the private IP. If we want to know the IP the request came from we need to look in the header for the \u00e2\u20ac\u0153X-Forwarded-For\u00e2\u20ac\u009d","title":"ELB"},{"location":"associate/developer/elb/#elastic-load-balancers","text":"Balances loads between multiple web servers Types: Application Load Balancer Application layer 7 OSI \u00e2\u20ac\u0153Smart Decisions\u00e2\u20ac\u009d Can see what request is doing to determine what needs done with request Can create advanced request routing Best suited for load balancing of HTTP and HTTPS Network Load Balancer Layer 4 Super Fast performance Best suited for TCP traffic Capable of handling millions of requests per seconds Use for extreme performance Most expensive Classic Load Balancer Not Recommended Legacy Purposes Tested on exam alot Meant for Legacy HTTP/HTTPS Sticky Sessions and X-Forwarded Can do layer 7 or layer 4 Load Balancer Errors: Error 504 Gateway has timed out if your application stops with 504 that means the application is having issues. This could be either at Web Server layer or at Database Layer. X-Forwarded-For Header: User (123.45.6.789) -> Load balancer (10.0.0.23) -> EC2 (10.0.0.23) The user sends a request to load balancer, load balancer does not use the user's public IP it hits the private IP for EC2 and the EC2 sees the private IP. If we want to know the IP the request came from we need to look in the header for the \u00e2\u20ac\u0153X-Forwarded-For\u00e2\u20ac\u009d","title":"Elastic Load Balancers"},{"location":"associate/developer/iam/","text":"IAM IAM allows you to manager users and their level of access to the AWS Console Centralized control of your AWS account Shared Access to your AWS account Granular Permissions Identity Federation Multi Factor Authentication Provide temporary access for users/devices and services, as necessary Allows you to set up your own password rotation policy Integrates with many AWS services. Supports PCI DSS Compliance Critical Terms: Users: End Users (Think People) Groups: Collection of users under one set of permissions Roles: Create roles and then assign them to AWS resources Policies: A document that defines one (or more) permissions Roles Roles allow access to resources without ACCESS keys Roles are preferred from a security perspective Roles are controlled by policies You can change a policy on a role and it will take immediate effect You can attach and detach roles to running EC2 instances without having to stop or terminate these instances","title":"IAM"},{"location":"associate/developer/iam/#iam","text":"IAM allows you to manager users and their level of access to the AWS Console Centralized control of your AWS account Shared Access to your AWS account Granular Permissions Identity Federation Multi Factor Authentication Provide temporary access for users/devices and services, as necessary Allows you to set up your own password rotation policy Integrates with many AWS services. Supports PCI DSS Compliance Critical Terms: Users: End Users (Think People) Groups: Collection of users under one set of permissions Roles: Create roles and then assign them to AWS resources Policies: A document that defines one (or more) permissions","title":"IAM"},{"location":"associate/developer/iam/#roles","text":"Roles allow access to resources without ACCESS keys Roles are preferred from a security perspective Roles are controlled by policies You can change a policy on a role and it will take immediate effect You can attach and detach roles to running EC2 instances without having to stop or terminate these instances","title":"Roles"},{"location":"associate/developer/kms/","text":"Key Management Service KMS Service to manage encryption keys for your data on AWS Integrated for seamless use with many AWS services Simple to encrypt data with keys you manage When to use: Whenever working with sensitive data Customer Data Financial Data Secrets Credentials Integrates with: S3 RDS DynamoDB Lambda EBS EFS CloudTrail (know who has been using keys and accessing data) Developer Tools CMK Customer Master Key Can Encrypt and decrypt data up to 4KB Used to generate encrypt and decrupt Data Ke Data Key Used to encrypt data Known as Envelope Encryption Symmetric Keys Single key for both encrypt and decrypt Asymetric Keys Public and private keypair that can be used for encrypt/decrypt or sign/verify If you want people outside your AWS IAM to use you will need to use public key in Asymetric CMK Exam tips Can use Alias to refer to CMK Has Creation Date Has description Has Key State (Enabled, Disabled, Pending, Deletion, Unavaible) Key Material (Customer Provided, KMS Provided) Stays Inside KMS Setting up CMK (Alias --> Description --> Key Material) Key Adminstration Permissions (Users --> Roles --> Admin Permissions) Users and roles who can administer key Key Usage Permissions (Users --> Roles --> Admin Permission) users and roles who will use key AWS-Managed CMK Created by AWS for interaction with AWS services Customer-Manged CMK Keys created and managed by users DataKey Used to encrypt and decrypt data Can be generated from CMK KMS API Calls aws kms encrypt cant take name of file to encrypt output name to put encrypted file creates a sipher text output aws kms decrypt used to decrypt encrypted file decrypts cipher text back to plain text aws kms re-encrypt allows rotation of encrypted files keys decrypts then re-encrypts with new key aws kms enable-key-rotation Allows AWS to rotate your key on annual basis aws kms generate-data-key Creates a data key so you can encrypt data above 4KB Envelope Encryption Process for encrypting your data for files over 4KB in size How to get one Use CMK to generate Data-key Why use it Network When you encrypt data directly with KMS it must be transferred over the network Performance With envelope encryption, only the data key goes over the netwoek not your data Benefits The data key is used locally in your application or AWS servic. Avoiding the need to transfer large amounts of data to KMS","title":"KMS"},{"location":"associate/developer/kms/#key-management-service-kms","text":"Service to manage encryption keys for your data on AWS Integrated for seamless use with many AWS services Simple to encrypt data with keys you manage When to use: Whenever working with sensitive data Customer Data Financial Data Secrets Credentials Integrates with: S3 RDS DynamoDB Lambda EBS EFS CloudTrail (know who has been using keys and accessing data) Developer Tools","title":"Key Management Service KMS"},{"location":"associate/developer/kms/#cmk","text":"Customer Master Key Can Encrypt and decrypt data up to 4KB Used to generate encrypt and decrupt Data Ke Data Key Used to encrypt data Known as Envelope Encryption Symmetric Keys Single key for both encrypt and decrypt Asymetric Keys Public and private keypair that can be used for encrypt/decrypt or sign/verify If you want people outside your AWS IAM to use you will need to use public key in Asymetric","title":"CMK"},{"location":"associate/developer/kms/#cmk-exam-tips","text":"Can use Alias to refer to CMK Has Creation Date Has description Has Key State (Enabled, Disabled, Pending, Deletion, Unavaible) Key Material (Customer Provided, KMS Provided) Stays Inside KMS Setting up CMK (Alias --> Description --> Key Material) Key Adminstration Permissions (Users --> Roles --> Admin Permissions) Users and roles who can administer key Key Usage Permissions (Users --> Roles --> Admin Permission) users and roles who will use key AWS-Managed CMK Created by AWS for interaction with AWS services Customer-Manged CMK Keys created and managed by users DataKey Used to encrypt and decrypt data Can be generated from CMK","title":"CMK Exam tips"},{"location":"associate/developer/kms/#kms-api-calls","text":"aws kms encrypt cant take name of file to encrypt output name to put encrypted file creates a sipher text output aws kms decrypt used to decrypt encrypted file decrypts cipher text back to plain text aws kms re-encrypt allows rotation of encrypted files keys decrypts then re-encrypts with new key aws kms enable-key-rotation Allows AWS to rotate your key on annual basis aws kms generate-data-key Creates a data key so you can encrypt data above 4KB","title":"KMS API Calls"},{"location":"associate/developer/kms/#envelope-encryption","text":"Process for encrypting your data for files over 4KB in size How to get one Use CMK to generate Data-key Why use it Network When you encrypt data directly with KMS it must be transferred over the network Performance With envelope encryption, only the data key goes over the netwoek not your data Benefits The data key is used locally in your application or AWS servic. Avoiding the need to transfer large amounts of data to KMS","title":"Envelope Encryption"},{"location":"associate/developer/lambda/","text":"Lambda Lambda is a compute service where you can upload your code and create a lambda function. AWS lambda takes care of provisioning and managing the servers that you use to run the code. Removes the need to worry about hardware, Operating systems, application layers, etc. Just worry about code Can be used as: An event-driven compute service where AWS lambda runs your code in response to events. Could be changes to data in s3, or dynamodb, etc As compute service to respond to HTTP request using Amazon API Gateway Languages supported by lambda NodeJS Java Python C# Go Ruby Powershell Lambda Pricing Priced on number of request First 1 million requests are free. Then $0.20 per 1 million request thereafter Duration Duration is calculated from time code begins executing until it returns or terminates This is rounded up to the nearest 100ms price also depends on amount of memoyr you allocate to your function ($0.00001667 per GB-second) Lambda Highlights No servers! Continous Scaling Super super cheap (A Cloud Gurus site is less than $1.00 a month) Lambda Exam Tips Lambda scales out (NOT up) automatically Millions of functions running in parrallel Will not increase memory the function uses Lambda functions are independent (1 event = 1 function) Lambda is serverless Also remember it is a compute service Know what services are serverless Lambda S3 API Gateway DynamoDB SNS Kinesis Lambda functions can trigger other lambda functions 1 event can = x functions if function triggers other functions Architectures can get extreamly complicated AWS X-ray allows you to debug Lambda Lambda can do things globally they are not limited to their regions Know your triggers Can have multiple versions of lambda functions### API Gateway What is an API An API is a an application programming interface Takes request does sends it somewhere, gets a response then returns response to whoever made the original request. Types of APIs REST APIs (REpresentational State Transfer) Uses JSON (typically) SOAP APIs (Simple Object Access Protocol) Uses XML Not very simple## Serverless Brief history Data Center --> IAAS --> PAAS --> Containers --> Serverless AWS released EC2 2006 (Birth Of IAAS) Azure releases Platform As A Service (PAAS) Then containers came about and gave lightweigh alternative to server Lambda was release and serverless computing was born No need to worry about anything but code Every Alexa command is just Lambda speaking back Latest version will always use $latest Qualified version will use $latest, unqualified will not have it Versions are immutable (CANNOT be changed) CANNOT split traffic with $latest instead you need to create an alias to latest Lambda Triggers (TODO) Lambda Versioning When versioning you can publish more than one version of your lambda functions After version is published it is immutable Latest is the only version that can be edited ARN types: Qualified ARN Does Have version at the end Unqualified ARN Does not have version at end Aliases can be used to point to lambda versions","title":"Lambda"},{"location":"associate/developer/lambda/#lambda","text":"Lambda is a compute service where you can upload your code and create a lambda function. AWS lambda takes care of provisioning and managing the servers that you use to run the code. Removes the need to worry about hardware, Operating systems, application layers, etc. Just worry about code Can be used as: An event-driven compute service where AWS lambda runs your code in response to events. Could be changes to data in s3, or dynamodb, etc As compute service to respond to HTTP request using Amazon API Gateway Languages supported by lambda NodeJS Java Python C# Go Ruby Powershell","title":"Lambda"},{"location":"associate/developer/lambda/#lambda-pricing","text":"Priced on number of request First 1 million requests are free. Then $0.20 per 1 million request thereafter Duration Duration is calculated from time code begins executing until it returns or terminates This is rounded up to the nearest 100ms price also depends on amount of memoyr you allocate to your function ($0.00001667 per GB-second)","title":"Lambda Pricing"},{"location":"associate/developer/lambda/#lambda-highlights","text":"No servers! Continous Scaling Super super cheap (A Cloud Gurus site is less than $1.00 a month)","title":"Lambda Highlights"},{"location":"associate/developer/lambda/#lambda-exam-tips","text":"Lambda scales out (NOT up) automatically Millions of functions running in parrallel Will not increase memory the function uses Lambda functions are independent (1 event = 1 function) Lambda is serverless Also remember it is a compute service Know what services are serverless Lambda S3 API Gateway DynamoDB SNS Kinesis Lambda functions can trigger other lambda functions 1 event can = x functions if function triggers other functions Architectures can get extreamly complicated AWS X-ray allows you to debug Lambda Lambda can do things globally they are not limited to their regions Know your triggers Can have multiple versions of lambda functions### API Gateway","title":"Lambda Exam Tips"},{"location":"associate/developer/lambda/#what-is-an-api","text":"An API is a an application programming interface Takes request does sends it somewhere, gets a response then returns response to whoever made the original request.","title":"What is an API"},{"location":"associate/developer/lambda/#types-of-apis","text":"REST APIs (REpresentational State Transfer) Uses JSON (typically) SOAP APIs (Simple Object Access Protocol) Uses XML Not very simple## Serverless Brief history Data Center --> IAAS --> PAAS --> Containers --> Serverless AWS released EC2 2006 (Birth Of IAAS) Azure releases Platform As A Service (PAAS) Then containers came about and gave lightweigh alternative to server Lambda was release and serverless computing was born No need to worry about anything but code Every Alexa command is just Lambda speaking back Latest version will always use $latest Qualified version will use $latest, unqualified will not have it Versions are immutable (CANNOT be changed) CANNOT split traffic with $latest instead you need to create an alias to latest","title":"Types of APIs"},{"location":"associate/developer/lambda/#lambda-triggers-todo","text":"","title":"Lambda Triggers (TODO)"},{"location":"associate/developer/lambda/#lambda-versioning","text":"When versioning you can publish more than one version of your lambda functions After version is published it is immutable Latest is the only version that can be edited ARN types: Qualified ARN Does Have version at the end Unqualified ARN Does not have version at end Aliases can be used to point to lambda versions","title":"Lambda Versioning"},{"location":"associate/developer/rds/","text":"RDS (OLTP) Relational databases are a compilation of tables that have rows and columns Relational Database Types: SQL Server Oracle MySQL Server PostgreSQL Aurora (Amazon\u00e2\u20ac\u2122s proprietary RDS) MariaDB Non Relational Database: Database with: Collection = Table Document = Row Key Value pairs = Fields Data does not need to be predefined Data warehousing Used for business intelligence Cognos Jaspersoft SQL Server Oracle Hyperion Used for data queries that are very heavy and should be done separate from production database Online Transaction Processing OLTP Simple transactions (happen frequently) Insert into table Redshift Online Analytics Processing OLAP (happens occasionally) More complex analysis Sum of radios sold in EMEA and profit from each ElastiCache Web service that makes it easy to deploy operate and scale in memory cache in cloud Take load off database by using cache memory Supports two open-source in-memory engines: Memcached Redis Aurora is not available on Free Tier RDS does not give public IPv4 only a DNS record Multi-AZ & Read Replicas Backups Automated backups: Will allow you ro recover your database to any point in a time within a \u00e2\u20ac\u0153retention period\u00e2\u20ac\u009d Automated Backups will take a full daily snapshot and will also store transaction logs throughout the day When you do a recovery AWS will choose the most recent daily back up and then apply transaction logs relevant to that day This allows for a point in time recovery down to a second within the retention period Retention periods are between 1 - 35 days Enabled by default Backup data stored in S3 You get free storage space equal to the size of your database Backups are taken within a defined window and during that time the I/O may experience latency Will be deleted if original DB deleted Snapshots Snapshots are done manually (user initiated) Will always be stored after deletion of original instance When restoring from snapshot the restored version will be a completely separate database with its own endpoint Encryption Uses the AWS Key Management Service (KMS) Once RDS is encrypted the data stored at rest in underlying storage is encrypted as are its automated backups and read replicas and snapshots Currently encrypting an existing DB instance is not supported, you would need to create snapshot make a copy of snapshot and encrypt the copy Read Replicas (Used For Performance) Done Asynchronously Create Read ONLY copy of production database Can have 5 read replicas per database by default Scale out DB to spread load across read replicas Can have read replicas of read replicas MUST have automatic backups turned on in order to deploy a read replica Read replicas can be promoted to be their own databases This breaks replication Read replicas can be in different AZ or regions Available for: MySQL Server PostgreSQL MariaDB Aurora NOT Available for: SQL Server Oracle Multi-AZ (Disaster Recovery ONLY) Done Synchronously RDS makes copy of all transaction to a copy of the Database in another AZ Designed for Disaster recovery AWS handles replication for us DNS will change if a database disaster is detected. Available for: SQL Server Oracle MySQL Server PostgreSQL MariaDB Aurora (Done by default) Elasticache Web service that makes it easy to deploy, operate and scale an in-memory cache in the cloud Faster than using the disk speeds Significantly support latency for read heavy workloads Improves performance by storing critical pieces of data in memory for low latency access Types: Memcached Widely adopted memory object caching system Elasticache protocol compliant with Memcached Use when not concerned with redundancy Redis Popular open-source in-memory key-value store that supports data structures such as sorted sets and lists Elasticache supports Master / Slave replication and Multi-AZ which can be used to achieve cross AZ redundancy Use when you want AZ redundancy Differences: Elasticache manages Redis more like a relational database because of replication and persistence features of Redis Redis ElastiCache clusters are managed as stateful entities that include failover. Memcached is designed as pure caching solution with no persistence similar to auto scaling with EC2 Nodes with Memcached are expendable and autoraplacable. Use Cases: Object Caching is primary goal (Memcached) Need simple caching modell (Memcached) Running large cache nodes and require multithreaded performance with multi cores (Memcached) Need to scale cache horizontally with growth (Memcached) More advanced data types (Redis) Sorting and ranking datasets in memory (Redis) Persistence of key store information (Redis) Run in multi-AZ with failover (Redis)","title":"Relational Databases"},{"location":"associate/developer/rds/#rds-oltp","text":"Relational databases are a compilation of tables that have rows and columns Relational Database Types: SQL Server Oracle MySQL Server PostgreSQL Aurora (Amazon\u00e2\u20ac\u2122s proprietary RDS) MariaDB Non Relational Database: Database with: Collection = Table Document = Row Key Value pairs = Fields Data does not need to be predefined Data warehousing Used for business intelligence Cognos Jaspersoft SQL Server Oracle Hyperion Used for data queries that are very heavy and should be done separate from production database Online Transaction Processing OLTP Simple transactions (happen frequently) Insert into table","title":"RDS (OLTP)"},{"location":"associate/developer/rds/#redshift","text":"Online Analytics Processing OLAP (happens occasionally) More complex analysis Sum of radios sold in EMEA and profit from each","title":"Redshift"},{"location":"associate/developer/rds/#elasticache","text":"Web service that makes it easy to deploy operate and scale in memory cache in cloud Take load off database by using cache memory Supports two open-source in-memory engines: Memcached Redis Aurora is not available on Free Tier RDS does not give public IPv4 only a DNS record","title":"ElastiCache"},{"location":"associate/developer/rds/#multi-az-read-replicas","text":"Backups Automated backups: Will allow you ro recover your database to any point in a time within a \u00e2\u20ac\u0153retention period\u00e2\u20ac\u009d Automated Backups will take a full daily snapshot and will also store transaction logs throughout the day When you do a recovery AWS will choose the most recent daily back up and then apply transaction logs relevant to that day This allows for a point in time recovery down to a second within the retention period Retention periods are between 1 - 35 days Enabled by default Backup data stored in S3 You get free storage space equal to the size of your database Backups are taken within a defined window and during that time the I/O may experience latency Will be deleted if original DB deleted Snapshots Snapshots are done manually (user initiated) Will always be stored after deletion of original instance When restoring from snapshot the restored version will be a completely separate database with its own endpoint Encryption Uses the AWS Key Management Service (KMS) Once RDS is encrypted the data stored at rest in underlying storage is encrypted as are its automated backups and read replicas and snapshots Currently encrypting an existing DB instance is not supported, you would need to create snapshot make a copy of snapshot and encrypt the copy Read Replicas (Used For Performance) Done Asynchronously Create Read ONLY copy of production database Can have 5 read replicas per database by default Scale out DB to spread load across read replicas Can have read replicas of read replicas MUST have automatic backups turned on in order to deploy a read replica Read replicas can be promoted to be their own databases This breaks replication Read replicas can be in different AZ or regions Available for: MySQL Server PostgreSQL MariaDB Aurora NOT Available for: SQL Server Oracle Multi-AZ (Disaster Recovery ONLY) Done Synchronously RDS makes copy of all transaction to a copy of the Database in another AZ Designed for Disaster recovery AWS handles replication for us DNS will change if a database disaster is detected. Available for: SQL Server Oracle MySQL Server PostgreSQL MariaDB Aurora (Done by default)","title":"Multi-AZ &amp; Read Replicas"},{"location":"associate/developer/rds/#elasticache_1","text":"Web service that makes it easy to deploy, operate and scale an in-memory cache in the cloud Faster than using the disk speeds Significantly support latency for read heavy workloads Improves performance by storing critical pieces of data in memory for low latency access Types: Memcached Widely adopted memory object caching system Elasticache protocol compliant with Memcached Use when not concerned with redundancy Redis Popular open-source in-memory key-value store that supports data structures such as sorted sets and lists Elasticache supports Master / Slave replication and Multi-AZ which can be used to achieve cross AZ redundancy Use when you want AZ redundancy Differences: Elasticache manages Redis more like a relational database because of replication and persistence features of Redis Redis ElastiCache clusters are managed as stateful entities that include failover. Memcached is designed as pure caching solution with no persistence similar to auto scaling with EC2 Nodes with Memcached are expendable and autoraplacable. Use Cases: Object Caching is primary goal (Memcached) Need simple caching modell (Memcached) Running large cache nodes and require multithreaded performance with multi cores (Memcached) Need to scale cache horizontally with growth (Memcached) More advanced data types (Redis) Sorting and ranking datasets in memory (Redis) Persistence of key store information (Redis) Run in multi-AZ with failover (Redis)","title":"Elasticache"},{"location":"associate/developer/route53/","text":"Route53 Amazon\u00e2\u20ac\u2122s DNS service Allows you to map domain names to EC2 instances Load Balancers S3 Buckets Naked domain is the domain excluding \u00e2\u20ac\u02dcwww\u00e2\u20ac\u2122 A and AAAA are only for the naked domain name","title":"Route 53"},{"location":"associate/developer/route53/#route53","text":"Amazon\u00e2\u20ac\u2122s DNS service Allows you to map domain names to EC2 instances Load Balancers S3 Buckets Naked domain is the domain excluding \u00e2\u20ac\u02dcwww\u00e2\u20ac\u2122 A and AAAA are only for the naked domain name","title":"Route53"},{"location":"associate/developer/s3/","text":"S3 Simple Storage Service (S3) Give devs and IT team secure, durable, scalable object storage Not for OS and database Data spread across multiple devices and facilities so these are HA Object based Objects can be 0 Bytest to 5 TB Larges size file that can transfer to S3 using PUT is 5 GB Unlimited Storage Files are stored in Buckets (similar to folder) S3 is a universal namespace (means they are a global service) When upload is successful you recieve a HTTP 200 status code Data consitency Read after Write consistency for PUTS of new Objects Means that as soon as file is uploaded it is available to read Eventual Consistency for overwrite PUTS and DELETES Means can take some time for changes to propegate S3 Under Hood S3 is object based and objects conists of the following Key (This is the name of an object) Value (This is the data, sequence of bytes) Version ID (Allows for versioning and rolling back) Metadata (Data about the data) Subresources - Bucket specfic configurations Bucket Policies, access control lists Cross Origin Resource Sharing (CORS) Transfer Acceleration Allows for increase transfer speed The Basics Built for 99.99% availability for S3 platform Amazon Gurantees 99.9% availability Amazon Gurantees 99.999999999% (the 11 9's) durability for S3 information This means they expect you to lose 1 file ever 10,000 years Tiered Storage Available Lifecycle Management Versioning Encryption Secure data access with Access Control lists Storage Tiers/Classes S3 (standard) 99.99% availability 11 9s durability Redundancy exists across multiple devices in multiple facilities and is designed to sustain loss of 2 facilities concurrently S3 IA (Infrequently Accessed) Data that is access less frequently but requires rapid access when needed Lower fee than S3 but chared with access data S3 One Zone IA Same as IA however data is stored in a single AZ Still contains 11 9s durability Only 99.5% availability Cost 20% less than regular S3 IA S3 Reduced Redundancy Storage Designed with only 99.99% durability 99.99% Availability Meant for data that is easily recreatable is lost Not offered in some regions AWS recommends NOT using this class Recommended to use S3 standard S3 standard price was reduce to be lower than this to help move people off S3 Glacier Designed for Data that is infrequently accessed Very Cheap Takes 3-5 hours to retrieve data S3 Deep Archive Glacier Glacier but more infrequent 12 hour retrieval time S3 Intelligent Tiering Designed for data with unknown or unpredictable access patterns 2 tiers frequent infrequent Objects are automatically moved around between tiers depending on access patterns 11 9s durability 99.99% accessibility Small Monthly fee for monitoring/automation Charges Storage per GB Requests (GET, PUT, COPY, ect) Storage Mangement Pricing Inventory, Analytics, Object Tags Data Management Pricing Free transfer in Charge for transfer in Transfer Acceleration Use of CloudFront to optimize speed S3 ACLs & Policies Access Control List ACL Per file/object basis By default only access to owner of file Fine grain access control Bucket Policies Documents that govern what settings for a given resource JSON objects Can use policy generator so you dont have to write JSON Will generate JSON code that you can copy and paste into policy editor Sometimes the policy generator will need to have a wildcard operator added to the resource S3 Encryption Encryption In Transit (Encrypt data being sent to and from bucket) Done with SSL/TLS At Rest (Encrypt data that is in bucket) Server Side Encryption S3 Managed Keys - SSE-S3 Amazon does everything Encrypts data Encrypts Keys AWS Key Management Service, Managed Keys, SSE-KMS Get a seperate key called \"Envelope Key\" This is key that encrypts the key Get Audit trail to see when and who has used encryption key Can use your own key Server side Encryption with customer Provided Key AWS manages encryption and decryption User manages their own keys Client Side Encryption User encrypts files themselves before uploading files into S3 Enforcing Encryption Every upload sends a PUT request Request header contains information for S3 to understand what needs to be done x-amz-server-side-encryption parameter included in request header if file needs encrypted at upload time Two options available x-amz-server-side-encryption: AES256 (SSE-S3 - S3 managed keys) x-amz-server-side-encryption: ams:kms (SSE-KMS - KMS managed keys) In order to enforce encryption all we need to do is make a bucket policy that denies any S3 PUT requests which do not include the x-amz-server-side-encryption How to enable Can be done via the the console (which is the easy way) Can be done with an S3 Bucket Policy (Written in JSON) Cross-Access-Resource-Sharing (CORS) Allows access from one resource (bucket) to another If you open to all you leave your resources exposed and vulnerable to attack S3 Perfomance Optimization (This has been deprecated advice since AWS increased S3 performance in 2018) By default S3 is designed to handle very high request rates If you are recieving over 100 PUT/LIST or 300 DELETE per second then you need to optimize This was changed in 2018 to 3500 put requests per second and 5500 get requests Mixed Request Type Workloads A mix of GET, PUT, DELETE, LIST Optimize by NOT using sequential keys as part of the file names Random over sequential This spreads the I/O on different partitions which spreads the I/O","title":"S3"},{"location":"associate/developer/s3/#s3","text":"Simple Storage Service (S3) Give devs and IT team secure, durable, scalable object storage Not for OS and database Data spread across multiple devices and facilities so these are HA Object based Objects can be 0 Bytest to 5 TB Larges size file that can transfer to S3 using PUT is 5 GB Unlimited Storage Files are stored in Buckets (similar to folder) S3 is a universal namespace (means they are a global service) When upload is successful you recieve a HTTP 200 status code Data consitency Read after Write consistency for PUTS of new Objects Means that as soon as file is uploaded it is available to read Eventual Consistency for overwrite PUTS and DELETES Means can take some time for changes to propegate S3 Under Hood S3 is object based and objects conists of the following Key (This is the name of an object) Value (This is the data, sequence of bytes) Version ID (Allows for versioning and rolling back) Metadata (Data about the data) Subresources - Bucket specfic configurations Bucket Policies, access control lists Cross Origin Resource Sharing (CORS) Transfer Acceleration Allows for increase transfer speed","title":"S3"},{"location":"associate/developer/s3/#the-basics","text":"Built for 99.99% availability for S3 platform Amazon Gurantees 99.9% availability Amazon Gurantees 99.999999999% (the 11 9's) durability for S3 information This means they expect you to lose 1 file ever 10,000 years Tiered Storage Available Lifecycle Management Versioning Encryption Secure data access with Access Control lists","title":"The Basics"},{"location":"associate/developer/s3/#storage-tiersclasses","text":"","title":"Storage Tiers/Classes"},{"location":"associate/developer/s3/#s3-standard","text":"99.99% availability 11 9s durability Redundancy exists across multiple devices in multiple facilities and is designed to sustain loss of 2 facilities concurrently","title":"S3 (standard)"},{"location":"associate/developer/s3/#s3-ia-infrequently-accessed","text":"Data that is access less frequently but requires rapid access when needed Lower fee than S3 but chared with access data","title":"S3 IA (Infrequently Accessed)"},{"location":"associate/developer/s3/#s3-one-zone-ia","text":"Same as IA however data is stored in a single AZ Still contains 11 9s durability Only 99.5% availability Cost 20% less than regular S3 IA","title":"S3 One Zone IA"},{"location":"associate/developer/s3/#s3-reduced-redundancy-storage","text":"Designed with only 99.99% durability 99.99% Availability Meant for data that is easily recreatable is lost Not offered in some regions AWS recommends NOT using this class Recommended to use S3 standard S3 standard price was reduce to be lower than this to help move people off","title":"S3 Reduced Redundancy Storage"},{"location":"associate/developer/s3/#s3-glacier","text":"Designed for Data that is infrequently accessed Very Cheap Takes 3-5 hours to retrieve data","title":"S3 Glacier"},{"location":"associate/developer/s3/#s3-deep-archive-glacier","text":"Glacier but more infrequent 12 hour retrieval time","title":"S3 Deep Archive Glacier"},{"location":"associate/developer/s3/#s3-intelligent-tiering","text":"Designed for data with unknown or unpredictable access patterns 2 tiers frequent infrequent Objects are automatically moved around between tiers depending on access patterns 11 9s durability 99.99% accessibility Small Monthly fee for monitoring/automation","title":"S3 Intelligent Tiering"},{"location":"associate/developer/s3/#charges","text":"Storage per GB Requests (GET, PUT, COPY, ect) Storage Mangement Pricing Inventory, Analytics, Object Tags Data Management Pricing Free transfer in Charge for transfer in Transfer Acceleration Use of CloudFront to optimize speed","title":"Charges"},{"location":"associate/developer/s3/#s3-acls-policies","text":"","title":"S3 ACLs &amp; Policies"},{"location":"associate/developer/s3/#access-control-list-acl","text":"Per file/object basis By default only access to owner of file Fine grain access control","title":"Access Control List ACL"},{"location":"associate/developer/s3/#bucket-policies","text":"Documents that govern what settings for a given resource JSON objects Can use policy generator so you dont have to write JSON Will generate JSON code that you can copy and paste into policy editor Sometimes the policy generator will need to have a wildcard operator added to the resource","title":"Bucket Policies"},{"location":"associate/developer/s3/#s3-encryption","text":"Encryption In Transit (Encrypt data being sent to and from bucket) Done with SSL/TLS At Rest (Encrypt data that is in bucket) Server Side Encryption S3 Managed Keys - SSE-S3 Amazon does everything Encrypts data Encrypts Keys AWS Key Management Service, Managed Keys, SSE-KMS Get a seperate key called \"Envelope Key\" This is key that encrypts the key Get Audit trail to see when and who has used encryption key Can use your own key Server side Encryption with customer Provided Key AWS manages encryption and decryption User manages their own keys Client Side Encryption User encrypts files themselves before uploading files into S3 Enforcing Encryption Every upload sends a PUT request Request header contains information for S3 to understand what needs to be done x-amz-server-side-encryption parameter included in request header if file needs encrypted at upload time Two options available x-amz-server-side-encryption: AES256 (SSE-S3 - S3 managed keys) x-amz-server-side-encryption: ams:kms (SSE-KMS - KMS managed keys) In order to enforce encryption all we need to do is make a bucket policy that denies any S3 PUT requests which do not include the x-amz-server-side-encryption How to enable Can be done via the the console (which is the easy way) Can be done with an S3 Bucket Policy (Written in JSON)","title":"S3 Encryption"},{"location":"associate/developer/s3/#cross-access-resource-sharing-cors","text":"Allows access from one resource (bucket) to another If you open to all you leave your resources exposed and vulnerable to attack","title":"Cross-Access-Resource-Sharing (CORS)"},{"location":"associate/developer/s3/#s3-perfomance-optimization","text":"(This has been deprecated advice since AWS increased S3 performance in 2018) By default S3 is designed to handle very high request rates If you are recieving over 100 PUT/LIST or 300 DELETE per second then you need to optimize This was changed in 2018 to 3500 put requests per second and 5500 get requests Mixed Request Type Workloads A mix of GET, PUT, DELETE, LIST Optimize by NOT using sequential keys as part of the file names Random over sequential This spreads the I/O on different partitions which spreads the I/O","title":"S3 Perfomance Optimization"},{"location":"associate/developer/serverless/","text":"Serverless Brief history Data Center --> IAAS --> PAAS --> Containers --> Serverless AWS released EC2 2006 (Birth Of IAAS) Azure releases Platform As A Service (PAAS) Then containers came about and gave lightweigh alternative to server Lambda was release and serverless computing was born No need to worry about anything but code Every Alexa command is just Lambda speaking back","title":"Serverless"},{"location":"associate/developer/serverless/#serverless","text":"Brief history Data Center --> IAAS --> PAAS --> Containers --> Serverless AWS released EC2 2006 (Birth Of IAAS) Azure releases Platform As A Service (PAAS) Then containers came about and gave lightweigh alternative to server Lambda was release and serverless computing was born No need to worry about anything but code Every Alexa command is just Lambda speaking back","title":"Serverless"},{"location":"associate/developer/step-functions/","text":"Step Functions Allows visualization of your serverless functions Provide graphical console to arrange and visualize components of your application as a series of steps Makes running multistep applications simple Automatically trigger and tracks each step, and retries when there are errors so your app executes in order and as expected Setp Functions log the state of each step so when things do go wrong you can diagnose and debug problems quickly","title":"Step Functions"},{"location":"associate/developer/step-functions/#step-functions","text":"Allows visualization of your serverless functions Provide graphical console to arrange and visualize components of your application as a series of steps Makes running multistep applications simple Automatically trigger and tracks each step, and retries when there are errors so your app executes in order and as expected Setp Functions log the state of each step so when things do go wrong you can diagnose and debug problems quickly","title":"Step Functions"},{"location":"associate/developer/xray/","text":"X-Ray X-Ray is a service that collects data about requests that you application serves Visualize serverless application See detailed information about any TRACE request to application and downstream services that get used How to use: Install X-Ray SDK in code SDK will then send JSON information to the X-Ray Daemon The Daemon will then send data to the X-Ray API SDK gives you Interceptors to add to your code to trace incoming HTTP requests Client handlers to instrument AWS SDK clients that your application uses to call other AWS services A HTTP client to use to instrument calls to other internal and external HTTP web services Integration Elastic Load Balancing AWS Lambda Amazon API Gateway Amazon Elastic Compute Cloud AWS Elastic Beanstalk Languages Supported Java Go Node js Python Ruby .NET","title":"X-Ray"},{"location":"associate/developer/xray/#x-ray","text":"X-Ray is a service that collects data about requests that you application serves Visualize serverless application See detailed information about any TRACE request to application and downstream services that get used How to use: Install X-Ray SDK in code SDK will then send JSON information to the X-Ray Daemon The Daemon will then send data to the X-Ray API SDK gives you Interceptors to add to your code to trace incoming HTTP requests Client handlers to instrument AWS SDK clients that your application uses to call other AWS services A HTTP client to use to instrument calls to other internal and external HTTP web services Integration Elastic Load Balancing AWS Lambda Amazon API Gateway Amazon Elastic Compute Cloud AWS Elastic Beanstalk Languages Supported Java Go Node js Python Ruby .NET","title":"X-Ray"},{"location":"practitioner/advantages-of-cloud/","text":"Six Advantages Of Cloud Computing Trade Capital Expense for variable expense Instead of investing heavily in data centers and servers before you use them you can pay for how much you are gonna use. Benefit from massive economies of scale you will never have the same purchasing power as Amazon. Stop guessing about capacity don't buy too much or too little. Increase speed and agility A cloud Guru platform was built in 3 weeks, using a new type of design called serverless architecture. It scales infinitely with demand. Stop spending money running and maintaining data centers Go global in minutes Infrastructure As A Service You manage the server which can be physical or virtual. As well as operating system, usually the data center provider will have no access to your server Platform As A Service Someone else manages the underlying hardware and operating systems. You focus on applications, someone else worries about security patching, updates, maintenance etc. Software As A Service Think of Gmail. All you do is manage your inbox and google handles everything else. Cloud Computing Deployment Types Public Cloud AWS, Azure, GCP Hybrid Mixture of public and private Private Cloud (On Premise) you host and manage it in your datacenters AWS - High Level Services Of Note* AWS Global Infrastructure AWS Cost Management Compute Databases Migration & Transfer Network & Content Delivery Security, Identity, & Compliance Storage CAPEX vs. OPEX Capex: Stands for Capital expenditure which is where you pay upfront and it is a fixed sunk in cost. Opex - Operational Expenditure which is where you pay for what you use. - Think about it like utilities (gas, electric) Pricing Policies Pay as you go Pay less when you reserve Pay even less per unit when using more Pay even less as AWS gross Custom pricing Fundamental Drivers Of Cost With AWS Compute Storage Data outbound","title":"Advantages Of Cloud"},{"location":"practitioner/advantages-of-cloud/#six-advantages-of-cloud-computing","text":"Trade Capital Expense for variable expense Instead of investing heavily in data centers and servers before you use them you can pay for how much you are gonna use. Benefit from massive economies of scale you will never have the same purchasing power as Amazon. Stop guessing about capacity don't buy too much or too little. Increase speed and agility A cloud Guru platform was built in 3 weeks, using a new type of design called serverless architecture. It scales infinitely with demand. Stop spending money running and maintaining data centers Go global in minutes","title":"Six Advantages Of Cloud Computing"},{"location":"practitioner/advantages-of-cloud/#infrastructure-as-a-service","text":"You manage the server which can be physical or virtual. As well as operating system, usually the data center provider will have no access to your server","title":"Infrastructure As A Service"},{"location":"practitioner/advantages-of-cloud/#platform-as-a-service","text":"Someone else manages the underlying hardware and operating systems. You focus on applications, someone else worries about security patching, updates, maintenance etc.","title":"Platform As A Service"},{"location":"practitioner/advantages-of-cloud/#software-as-a-service","text":"Think of Gmail. All you do is manage your inbox and google handles everything else.","title":"Software As A Service"},{"location":"practitioner/advantages-of-cloud/#cloud-computing-deployment-types","text":"Public Cloud AWS, Azure, GCP Hybrid Mixture of public and private Private Cloud (On Premise) you host and manage it in your datacenters","title":"Cloud Computing Deployment Types"},{"location":"practitioner/advantages-of-cloud/#aws-high-level-services-of-note","text":"AWS Global Infrastructure AWS Cost Management Compute Databases Migration & Transfer Network & Content Delivery Security, Identity, & Compliance Storage","title":"AWS - High Level Services Of Note*"},{"location":"practitioner/advantages-of-cloud/#capex-vs-opex","text":"Capex: Stands for Capital expenditure which is where you pay upfront and it is a fixed sunk in cost. Opex - Operational Expenditure which is where you pay for what you use. - Think about it like utilities (gas, electric)","title":"CAPEX vs. OPEX"},{"location":"practitioner/advantages-of-cloud/#pricing-policies","text":"Pay as you go Pay less when you reserve Pay even less per unit when using more Pay even less as AWS gross Custom pricing","title":"Pricing Policies"},{"location":"practitioner/advantages-of-cloud/#fundamental-drivers-of-cost-with-aws","text":"Compute Storage Data outbound","title":"Fundamental Drivers Of Cost With AWS"},{"location":"practitioner/cloudformation/","text":"CloudFormation Its a service that allows you to model and setup AWS resources. Focus more on the application and not managing the resources Create templates to describe needed resources FREE service (however resources provisioned are not)","title":"Cloud Formation"},{"location":"practitioner/cloudformation/#cloudformation","text":"Its a service that allows you to model and setup AWS resources. Focus more on the application and not managing the resources Create templates to describe needed resources FREE service (however resources provisioned are not)","title":"CloudFormation"},{"location":"practitioner/cloudfront/","text":"What is CloudFront A content delivery network (CDN) works in 3 parts: Edge Location Origin Distribution (name given to CDN which consists of a collection of edge locations) First users asks for content from edge location then the edge location will go get file and server to user. Then any additional users get files from edge locations Types of distributions Web Distribution - Typically for Websites RTMP - Used for media streaming (CloudFront is discontinuing support for RTMP distributions on December 31, 2020. For more information, please read the announcement.)","title":"Cloud Front"},{"location":"practitioner/cloudfront/#what-is-cloudfront","text":"A content delivery network (CDN) works in 3 parts: Edge Location Origin Distribution (name given to CDN which consists of a collection of edge locations) First users asks for content from edge location then the edge location will go get file and server to user. Then any additional users get files from edge locations","title":"What is CloudFront"},{"location":"practitioner/cloudfront/#types-of-distributions","text":"Web Distribution - Typically for Websites RTMP - Used for media streaming (CloudFront is discontinuing support for RTMP distributions on December 31, 2020. For more information, please read the announcement.)","title":"Types of distributions"},{"location":"practitioner/cloudwatch/","text":"Cloudwatch Monitor services for AWS resources and applications on AWS. Compute EC2 Instances Autoscaling Groups Elastic Load Balancers Route 53 Health checks Storage and content deliver EBS Volume Storage gateway Collectd type metrics Monitors every 5 mins by default Can trigger notifications Can change intervals for checks. AWS Systems Manager Monitor EC2 instances at scale, or allows you to monitor EC2 Fleet (many EC2s) Installs piece of software on each VM Use system manager to run command across ALL EC2 instances Also works on for on premise machines Integrates with cloudwatch to give dashboard for everything","title":"Cloudwatch"},{"location":"practitioner/cloudwatch/#cloudwatch","text":"Monitor services for AWS resources and applications on AWS. Compute EC2 Instances Autoscaling Groups Elastic Load Balancers Route 53 Health checks Storage and content deliver EBS Volume Storage gateway Collectd type metrics Monitors every 5 mins by default Can trigger notifications Can change intervals for checks. AWS Systems Manager Monitor EC2 instances at scale, or allows you to monitor EC2 Fleet (many EC2s) Installs piece of software on each VM Use system manager to run command across ALL EC2 instances Also works on for on premise machines Integrates with cloudwatch to give dashboard for everything","title":"Cloudwatch"},{"location":"practitioner/databases/","text":"Databases Relational Databases on AWS - RDS: SQL Server Oracle MySQL Server PostgreSQL Aurora (amazon\u2019s own) MariaDB Can have multiple availability zones. Can have Read Replicas for enhanced Performance Multiple AZ\u2019s are for disaster recovery Read Replicas are to increase performance NON-Relational Database on AWS Columns in table can vary Previous columns will not affect other rows in the database Amazons NON-Relational Database is called DynamoDB Online Transaction Processing (OLTP) Pulls up a row of data such as Name, Date, Address to deliver to, etc. Basically takes/inserts a row from database Online Analytics Processing (OLAP) Pulls huge number of records Massive performance needed Data warehouse created to solve this. Data-warehouse Use different architecture Designed to handle large scale calculations of data away from the database so that database performance is not affected. AMAZON'S Redshift ElastiCache Web service that makes it easy to deploy, operate and scale an in-memory cache in the cloud. Improve performance of web application Caches most common queries to return data to users. Takes massive load off database queires Comes in Memcached and Redis Graph database Amazon Neptune is Amazon\u2019s graph database","title":"Databases"},{"location":"practitioner/databases/#databases","text":"Relational Databases on AWS - RDS: SQL Server Oracle MySQL Server PostgreSQL Aurora (amazon\u2019s own) MariaDB Can have multiple availability zones. Can have Read Replicas for enhanced Performance Multiple AZ\u2019s are for disaster recovery Read Replicas are to increase performance","title":"Databases"},{"location":"practitioner/databases/#non-relational-database-on-aws","text":"Columns in table can vary Previous columns will not affect other rows in the database Amazons NON-Relational Database is called DynamoDB","title":"NON-Relational Database on AWS"},{"location":"practitioner/databases/#online-transaction-processing-oltp","text":"Pulls up a row of data such as Name, Date, Address to deliver to, etc. Basically takes/inserts a row from database","title":"Online Transaction Processing (OLTP)"},{"location":"practitioner/databases/#online-analytics-processing-olap","text":"Pulls huge number of records Massive performance needed Data warehouse created to solve this.","title":"Online Analytics Processing (OLAP)"},{"location":"practitioner/databases/#data-warehouse","text":"Use different architecture Designed to handle large scale calculations of data away from the database so that database performance is not affected. AMAZON'S Redshift","title":"Data-warehouse"},{"location":"practitioner/databases/#elasticache","text":"Web service that makes it easy to deploy, operate and scale an in-memory cache in the cloud. Improve performance of web application Caches most common queries to return data to users. Takes massive load off database queires Comes in Memcached and Redis","title":"ElastiCache"},{"location":"practitioner/databases/#graph-database","text":"Amazon Neptune is Amazon\u2019s graph database","title":"Graph database"},{"location":"practitioner/ebs/","text":"What is EBS Virtual Disk in The Cloud. Types: SSD General Purpose SSD (GP2) - balances price and performance for a wide variety of workloads Provisoned IOPS SSD (I01) - Highest performance SSD volume for mission-critical low-latency or high-throughput workloads THERE IS ALSO A (IO2) Magnetic Throughput Optimiazed HDD (ST1) - Low cost HDD volume designed for frequently accessed throughput-intense workloads. Cold HDD (SC1) - Lowest Cost HDD volume designed for less frequently accessed workloads Magnetic - Previous Generation","title":"EBS"},{"location":"practitioner/ebs/#what-is-ebs","text":"Virtual Disk in The Cloud. Types: SSD General Purpose SSD (GP2) - balances price and performance for a wide variety of workloads Provisoned IOPS SSD (I01) - Highest performance SSD volume for mission-critical low-latency or high-throughput workloads THERE IS ALSO A (IO2) Magnetic Throughput Optimiazed HDD (ST1) - Low cost HDD volume designed for frequently accessed throughput-intense workloads. Cold HDD (SC1) - Lowest Cost HDD volume designed for less frequently accessed workloads Magnetic - Previous Generation","title":"What is EBS"},{"location":"practitioner/ec2/","text":"EC2 Elastic Compute Cloud Oldest services Virtual server or servers in cloud. Web service that provides resizable compute capacity in the cloud. Amazon EC2 reduces the time required to obtain and boot new server instances to minutes allowing you to quickly scale capacity both up and down as your needs change EC2 Pricing Models On Demand (allows you to pay a fixed rate by the hour (or second) with no commitment) Reserved (Provides you with a capacity reservation and offers a significant discount on the hourly charge for an instance. Contract terms are 1 or 3 years) Spot ( Enables you to bid a price you want to pay for instance capacity) NOTE: if amazon EC2 terminates spot instance because of pricing change during your hour of use you will NOT be charged however if you terminate the instance early you are charged for any hour which the instance ran. Dedicated Hosts (Physical EC2 server dedicated for your use.) EC2 Pricing Clock Hours of Server Time Instance Type Pricing Model Number of Instances Load Balancing Detailed Monitoring Auto Scaling Elastic IP Addresses Operating Systems and Software Packages Pricing Models On Demand Reserved Spot Dedicated Hosts Lambda Pricing Request Pricing Free Tier: 1 million requests per month $0.20 per 1 mil AWS Budgets: Gives ability to set custom budgets that alert you when your costs or usage exceed (or are forecasted to exceed your budgeted amount) Used to budget costs before they are incurred Silly Acronym To Remember EC2 Types : FIGHT DR MCPXZ F - For FPGA I - FOR IOPS G - Graphics H - High Disk Throughput T - Cheap general purpose D - For Density R - For RAM M - Main choice for general purpose apps C - For Compute P - Graphics X - Extreme Memory Z - Extreme memory and CPU","title":"EC2"},{"location":"practitioner/ec2/#ec2-elastic-compute-cloud","text":"Oldest services Virtual server or servers in cloud. Web service that provides resizable compute capacity in the cloud. Amazon EC2 reduces the time required to obtain and boot new server instances to minutes allowing you to quickly scale capacity both up and down as your needs change","title":"EC2 Elastic Compute Cloud"},{"location":"practitioner/ec2/#ec2-pricing-models","text":"On Demand (allows you to pay a fixed rate by the hour (or second) with no commitment) Reserved (Provides you with a capacity reservation and offers a significant discount on the hourly charge for an instance. Contract terms are 1 or 3 years) Spot ( Enables you to bid a price you want to pay for instance capacity) NOTE: if amazon EC2 terminates spot instance because of pricing change during your hour of use you will NOT be charged however if you terminate the instance early you are charged for any hour which the instance ran. Dedicated Hosts (Physical EC2 server dedicated for your use.)","title":"EC2 Pricing Models"},{"location":"practitioner/ec2/#ec2-pricing","text":"Clock Hours of Server Time Instance Type Pricing Model Number of Instances Load Balancing Detailed Monitoring Auto Scaling Elastic IP Addresses Operating Systems and Software Packages Pricing Models On Demand Reserved Spot Dedicated Hosts Lambda Pricing Request Pricing Free Tier: 1 million requests per month $0.20 per 1 mil AWS Budgets: Gives ability to set custom budgets that alert you when your costs or usage exceed (or are forecasted to exceed your budgeted amount) Used to budget costs before they are incurred","title":"EC2 Pricing"},{"location":"practitioner/ec2/#silly-acronym-to-remember-ec2-types-fight-dr-mcpxz","text":"F - For FPGA I - FOR IOPS G - Graphics H - High Disk Throughput T - Cheap general purpose D - For Density R - For RAM M - Main choice for general purpose apps C - For Compute P - Graphics X - Extreme Memory Z - Extreme memory and CPU","title":"Silly Acronym To Remember EC2 Types : FIGHT DR MCPXZ"},{"location":"practitioner/elastic-beanstalk/","text":"Elastic BeanStalk Deploy Applications to cloud Need no knowledge on AWS just upload code FREE service (however resources provisioned are not)","title":"Elastic Beanstalk"},{"location":"practitioner/elastic-beanstalk/#elastic-beanstalk","text":"Deploy Applications to cloud Need no knowledge on AWS just upload code FREE service (however resources provisioned are not)","title":"Elastic BeanStalk"},{"location":"practitioner/exam-tip/","text":"Exam Tips Popular Exam Questions Name All the Compute Services: EC2 Elastic BeanStalk Lambda Lightsail Batch EC2 Image Builder AWS Outpost Serverless application Repository Traditional Computing vs Cloud Computing IT assets as Provisioned Resources Global, Available, and Scalable Capacity Higher level Managed Services Built in security Architecting For Cost Operations on AWS Name Global Services: IAM Route 53 CloudFront SNS SES Give Global view BUT are regional S3 AWS Services used on Premise Snowball (Typically 80 TB in size AWS ships to you and you ship back to move data) Snowball Edge (Similar however has CPU and can deploy lambda on premise) Storage Gateway (Stays on premise, allows caching files inside datacenter that replicates to S3) CodeDeploy (deploy applications on EC2 on premise) Opsworks (similar to elastic beanstalk. Used to deploy) IoT Greengrass (connects devices to AWS cloud) Name Free Services: Amazon VPC Elastic Beanstalk Cloud Formation Identity Access Management (IAM) Auto Scaling Opsworks Consolidated Biling","title":"Exam Tips"},{"location":"practitioner/exam-tip/#exam-tips","text":"","title":"Exam Tips"},{"location":"practitioner/exam-tip/#popular-exam-questions","text":"Name All the Compute Services: EC2 Elastic BeanStalk Lambda Lightsail Batch EC2 Image Builder AWS Outpost Serverless application Repository Traditional Computing vs Cloud Computing IT assets as Provisioned Resources Global, Available, and Scalable Capacity Higher level Managed Services Built in security Architecting For Cost Operations on AWS Name Global Services: IAM Route 53 CloudFront SNS SES Give Global view BUT are regional S3 AWS Services used on Premise Snowball (Typically 80 TB in size AWS ships to you and you ship back to move data) Snowball Edge (Similar however has CPU and can deploy lambda on premise) Storage Gateway (Stays on premise, allows caching files inside datacenter that replicates to S3) CodeDeploy (deploy applications on EC2 on premise) Opsworks (similar to elastic beanstalk. Used to deploy) IoT Greengrass (connects devices to AWS cloud) Name Free Services: Amazon VPC Elastic Beanstalk Cloud Formation Identity Access Management (IAM) Auto Scaling Opsworks Consolidated Biling","title":"Popular Exam Questions"},{"location":"practitioner/lightsail/","text":"Lightsail Platform As A Service","title":"Light Sail"},{"location":"practitioner/lightsail/#lightsail","text":"Platform As A Service","title":"Lightsail"},{"location":"practitioner/load-balancers/","text":"Load Balancers Application Load Balancers Layer 7 aware (Meaning they can make intelligent decisions) Network Load Balancers Extreme Performance/Static IP Addresses Classic Load Balancers Test & Dev, Keep Costs Low","title":"Load Balancers"},{"location":"practitioner/load-balancers/#load-balancers","text":"","title":"Load Balancers"},{"location":"practitioner/load-balancers/#application-load-balancers","text":"Layer 7 aware (Meaning they can make intelligent decisions)","title":"Application Load Balancers"},{"location":"practitioner/load-balancers/#network-load-balancers","text":"Extreme Performance/Static IP Addresses","title":"Network Load Balancers"},{"location":"practitioner/load-balancers/#classic-load-balancers","text":"Test & Dev, Keep Costs Low","title":"Classic Load Balancers"},{"location":"practitioner/route53/","text":"Route 53 Amazon\u2019s DNS service It is Global like IAM and S3 Can direct traffic all over the world Can Register Domain Name","title":"Route 53"},{"location":"practitioner/route53/#route-53","text":"Amazon\u2019s DNS service It is Global like IAM and S3 Can direct traffic all over the world Can Register Domain Name","title":"Route 53"},{"location":"practitioner/s3/","text":"What is S3 Simple Service Storage (S3) one of the oldest services Provides developers and IT teams with secure, durable, highly-scalable object storage. Amazon S3 is easy to use, with a simple web services interface to store and retrieve S3 is safe place to store files Object-based storage Block based storage would be for operating systems (NOT s3) Files can be from 0bytes to 5 TB Unlimited storage Files are stored in Buckets (Folders in cloud) S3 is a universal Namespace so name must be unique GLOBALLY will always be prefixed with https://s3-region... Objects are files that consist of: Key (simply the name of the object) Value (Data that made up of sequence of Bytes) Version ID Metadata Subresources Access Control Lists Torrent S3 NEED TO KNOW Exam Tips How does consistency work for S3 Read after Write consistency for PUTS of new Objects Eventual Consistency for overwrite PUTS and DELETES (can take some time to propagate) If writing file, put a file into S3 you can immediately read that data. If you update existing file or delete file you may get an older version. Basically changes can take some time to propagate to S3 S3 has following guarantees 99.99% availability for S3 platform But amazon only Gurantees 99.9% availability AMAZON does guarantee 99.999999999% durability (the 11 9's) So very unlikely to lose File To Calculate: Number of seconds in any given months and multiply it by 99.99% S3 has the following features Tiered Storage Available Lifecycle Management Versioning Encryption Secure your data using Access Control Lists and Bucket Policies S3 Storage Classes S3 - Standard (11 9's ) S3 - IA (RAPID access) S3 - One Zone - IA S3 - Intelligent Tiering (using machine learning to determine what you need) S3 - Glacier (secure, durable low cost data archiving) S3 - Glacier Deep Archive (takes 12 hours to retrieve SUPER cheap) What are you charged for with S3? Storage Requests Storage Management pricing Data Transfer pricing Transfer Acceleration Cross Region Replication Pricing S3 Transfer Acceleration enables fast and secure transfers of files over long distances between your end users and s3 buckets. (Users upload to edge sites then use Amazon intranet to upload) Restricting ACCESS in S3 Use Bucket Policies - Applies across the whole bucket Object Policies - Applies to individual files IAM Policies to Users and Groups - applies to users and groups Static Websites can be hosted in S3 Buckets Dynamic Websites CANNOT be hosted in S3 Buckets S3 buckets scale dynamically","title":"S3"},{"location":"practitioner/s3/#what-is-s3","text":"","title":"What is S3"},{"location":"practitioner/s3/#simple-service-storage-s3","text":"one of the oldest services Provides developers and IT teams with secure, durable, highly-scalable object storage. Amazon S3 is easy to use, with a simple web services interface to store and retrieve S3 is safe place to store files Object-based storage Block based storage would be for operating systems (NOT s3) Files can be from 0bytes to 5 TB Unlimited storage Files are stored in Buckets (Folders in cloud) S3 is a universal Namespace so name must be unique GLOBALLY will always be prefixed with https://s3-region... Objects are files that consist of: Key (simply the name of the object) Value (Data that made up of sequence of Bytes) Version ID Metadata Subresources Access Control Lists Torrent","title":"Simple Service Storage (S3)"},{"location":"practitioner/s3/#s3-need-to-know-exam-tips","text":"How does consistency work for S3 Read after Write consistency for PUTS of new Objects Eventual Consistency for overwrite PUTS and DELETES (can take some time to propagate) If writing file, put a file into S3 you can immediately read that data. If you update existing file or delete file you may get an older version. Basically changes can take some time to propagate to S3 S3 has following guarantees 99.99% availability for S3 platform But amazon only Gurantees 99.9% availability AMAZON does guarantee 99.999999999% durability (the 11 9's) So very unlikely to lose File To Calculate: Number of seconds in any given months and multiply it by 99.99%","title":"S3 NEED TO KNOW Exam Tips"},{"location":"practitioner/s3/#s3-has-the-following-features","text":"Tiered Storage Available Lifecycle Management Versioning Encryption Secure your data using Access Control Lists and Bucket Policies","title":"S3 has the following features"},{"location":"practitioner/s3/#s3-storage-classes","text":"S3 - Standard (11 9's ) S3 - IA (RAPID access) S3 - One Zone - IA S3 - Intelligent Tiering (using machine learning to determine what you need) S3 - Glacier (secure, durable low cost data archiving) S3 - Glacier Deep Archive (takes 12 hours to retrieve SUPER cheap)","title":"S3 Storage Classes"},{"location":"practitioner/s3/#what-are-you-charged-for-with-s3","text":"Storage Requests Storage Management pricing Data Transfer pricing Transfer Acceleration Cross Region Replication Pricing","title":"What are you charged for with S3?"},{"location":"practitioner/s3/#s3-transfer-acceleration","text":"enables fast and secure transfers of files over long distances between your end users and s3 buckets. (Users upload to edge sites then use Amazon intranet to upload)","title":"S3 Transfer Acceleration"},{"location":"practitioner/s3/#restricting-access-in-s3","text":"Use Bucket Policies - Applies across the whole bucket Object Policies - Applies to individual files IAM Policies to Users and Groups - applies to users and groups Static Websites can be hosted in S3 Buckets Dynamic Websites CANNOT be hosted in S3 Buckets S3 buckets scale dynamically","title":"Restricting ACCESS in S3"},{"location":"practitioner/support-plans/","text":"Support Plans Basic Free access to forums Developer experimenting with AWS. One primary contact to ask technical questions through Support Center and get response within 12-24 hours during local business hours 29/month Business Production use of AWS - 24x7 support by phone and chat. 1-hour response time to urgent support cases and help with common third party software. Full access to AWS Trusted advisor for optimizing your AWS infrastructure and access to AWS Support API for automating your support cases 100/month Enterprise Use Case: Mission-critical use of AWS Technical Account Manager (TAM) 15 minute response time. 15k month","title":"Support Plans"},{"location":"practitioner/support-plans/#support-plans","text":"","title":"Support Plans"},{"location":"practitioner/support-plans/#basic","text":"Free access to forums","title":"Basic"},{"location":"practitioner/support-plans/#developer","text":"experimenting with AWS. One primary contact to ask technical questions through Support Center and get response within 12-24 hours during local business hours 29/month","title":"Developer"},{"location":"practitioner/support-plans/#business","text":"Production use of AWS - 24x7 support by phone and chat. 1-hour response time to urgent support cases and help with common third party software. Full access to AWS Trusted advisor for optimizing your AWS infrastructure and access to AWS Support API for automating your support cases 100/month","title":"Business"},{"location":"practitioner/support-plans/#enterprise","text":"Use Case: Mission-critical use of AWS Technical Account Manager (TAM) 15 minute response time. 15k month","title":"Enterprise"},{"location":"practitioner/tags/","text":"Tags Key:Value pairs Metadata Tags can be inherited Specific Information Resource Groups objects that share one or more tags AWS Organizations & Consolidated Billing AWSO an account management service, consolidates AWS Consolidated Billing","title":"Tags"},{"location":"practitioner/tags/#tags","text":"Key:Value pairs Metadata Tags can be inherited Specific Information Resource Groups objects that share one or more tags AWS Organizations & Consolidated Billing AWSO an account management service, consolidates AWS Consolidated Billing","title":"Tags"},{"location":"practitioner/waf/","text":"AWS WAF & AWS Shield WAF protections from common exploits (Hackers) Shield protects from DDos, two tiers (DDos) Standard - Free, comes with all deployments Advanced - adds reporting, support for DDoS attacks, and cost protection Amazon Inspector Automatically assesses application for security vulnerabilities or deviations from best practice. Trusted Advisor Provides real time guidance on provisioning resources according to AWS best practices. Advices on Optimization, Performance, Security, Fault Tolerance Core Check and Recommendations - Free Full Trusted Advisor - Business and Enterprise Only Athena, serverless query service Query logs Business reports AWS cost and usage reports Queries on click-stream data Macie uses AI protects PII, security service","title":"WAF"},{"location":"practitioner/waf/#aws-waf-aws-shield","text":"WAF protections from common exploits (Hackers) Shield protects from DDos, two tiers (DDos) Standard - Free, comes with all deployments Advanced - adds reporting, support for DDoS attacks, and cost protection Amazon Inspector Automatically assesses application for security vulnerabilities or deviations from best practice. Trusted Advisor Provides real time guidance on provisioning resources according to AWS best practices. Advices on Optimization, Performance, Security, Fault Tolerance Core Check and Recommendations - Free Full Trusted Advisor - Business and Enterprise Only Athena, serverless query service Query logs Business reports AWS cost and usage reports Queries on click-stream data Macie uses AI protects PII, security service","title":"AWS WAF &amp; AWS Shield"},{"location":"practitioner/zones-and-regions/","text":"Zones and Regions Availability zone is datacenter ( one or more discrete data center each with redundant power networking and connectivity housed in separate facilities) Region is geographical area consisting of 2 or more availability zones (is a physical location in the world which consists of two or more AZs) Edge locations are endpoints for AWS which are used for caching content. Typically this consists of CloudFront, Amazon's Content Delivery Network (CDN) GovClouds are operated by US citizens on US soil. Only government and private businesses that pass screening checks can use it. Choosing the right AWS region Data Sovereignty Laws Latency to end users AWS Services (US east-1 primary Region for releases)","title":"Zones And Regions"},{"location":"practitioner/zones-and-regions/#zones-and-regions","text":"Availability zone is datacenter ( one or more discrete data center each with redundant power networking and connectivity housed in separate facilities) Region is geographical area consisting of 2 or more availability zones (is a physical location in the world which consists of two or more AZs) Edge locations are endpoints for AWS which are used for caching content. Typically this consists of CloudFront, Amazon's Content Delivery Network (CDN) GovClouds are operated by US citizens on US soil. Only government and private businesses that pass screening checks can use it.","title":"Zones and Regions"},{"location":"practitioner/zones-and-regions/#choosing-the-right-aws-region","text":"Data Sovereignty Laws Latency to end users AWS Services (US east-1 primary Region for releases)","title":"Choosing the right AWS region"}]}